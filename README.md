# ğŸ“˜ DocumentaÃ§Ã£o: Serverless RAG Chatbot (MVP)

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral e Stack TecnolÃ³gico](#1-visÃ£o-geral-e-stack-tecnolÃ³gico)
2. [Registro de DecisÃµes e DÃºvidas](#2-registro-de-decisÃµes-e-dÃºvidas-architecture-decision-record)
3. [Fluxo de Trabalho Git](#3-fluxo-de-trabalho-git-padrÃ£o-promiles)
4. [Roteiro de ImplementaÃ§Ã£o](#4-roteiro-de-implementaÃ§Ã£o-roadmap)
5. [ImplementaÃ§Ã£o TÃ©cnica de ReferÃªncia](#5-implementaÃ§Ã£o-tÃ©cnica-de-referÃªncia)
6. [Checklist de ValidaÃ§Ã£o Final](#6-checklist-de-validaÃ§Ã£o-final)
7. [Estrutura do Projeto](#7-estrutura-do-projeto)
8. [Como ComeÃ§ar](#8-como-comeÃ§ar)

---

## 1. VisÃ£o Geral e Stack TecnolÃ³gico

O objetivo Ã© criar um Chatbot de InteligÃªncia Artificial que responda perguntas baseadas em um documento PDF privado (RAG), com interface reativa e respostas via streaming.

### Frontend (AplicaÃ§Ã£o Web)
* **Framework:** **Nuxt 3** (Vue.js + TailwindCSS)
* **Gerenciamento de SessÃ£o:** **LocalStorage** (Navegador do Cliente)
* **ComunicaÃ§Ã£o:** `fetch` nativo com leitura de `ReadableStream`

### Backend (Serverless API)
* **Framework:** **Nuxt Nitro** (Server Routes - `/server/api`)
* **Runtime:** Node.js rodando em **AWS Lambda**
* **Acesso:** **Function URL** (Endpoint HTTPS direto, sem API Gateway complexo)
* **Streaming:** `InvokeMode: RESPONSE_STREAM`
* **Endpoints:**
    * `/api/ingest` - Upload e processamento de PDFs 
    * `/api/chat` - ConversaÃ§Ã£o com o chatbot (streaming de resposta)

### InteligÃªncia & Dados
* **LLM:** OpenAI `gpt-5-nano`
* **OrquestraÃ§Ã£o:** **LangChain.js** (Core & Community)
* **Banco de Conhecimento:** **Qdrant** (Vector Database)
    * *FunÃ§Ã£o:* Armazenar o PDF (chunks) e transformado em vetores

---

## 2. ğŸ§  Registro de DecisÃµes e DÃºvidas (Architecture Decision Record)

Esta seÃ§Ã£o detalha as dÃºvidas levantadas durante o planejamento e a soluÃ§Ã£o final adotada.

### 2.1. MemÃ³ria do Chat: Redis vs. LocalStorage vs. In-Memory
* **DÃºvida Levantada:** *"Devo usar Redis para o histÃ³rico? Posso usar variÃ¡vel global em Python/Node? O Qdrant salva o histÃ³rico? Banco nÃ£o relacional / relacional funciona aqui?"*
* **AnÃ¡lise:**
    * *Qdrant:* NÃ£o serve para histÃ³rico de conversa, serve apenas para conhecimento (PDF)
    * *In-Memory (variÃ¡vel global):* ImpossÃ­vel em AWS Lambda, pois a funÃ§Ã£o "morre" apÃ³s o uso (Stateless). VariÃ¡vel global Node seria perdida entre invocaÃ§Ãµes
    * *Banco Relacional (PostgreSQL, MySQL):* Funcionaria tecnicamente, mas Ã© "overkill" para MVP. Exige RDS (custo), gerenciamento de conexÃµes e esquema de dados
    * *Banco NÃ£o Relacional (DynamoDB, MongoDB):* TambÃ©m funcionaria, mas adiciona complexidade de queries e custo. DynamoDB seria serverless, mas precisa gerenciar TTL e cleanup
    * *Redis:* Seria a soluÃ§Ã£o robusta padrÃ£o para cache de sessÃ£o, mas adiciona custo (instÃ¢ncia paga) e complexidade de infraestrutura (VPC) desnecessÃ¡ria para um MVP
* **DecisÃ£o Final:** **Frontend-Driven History**
    * O Frontend guarda o array de mensagens no LocalStorage
    * A cada nova pergunta, o Frontend envia o **histÃ³rico completo** no `body` da requisiÃ§Ã£o
    * O Backend recebe tudo que precisa no request, processa e responde (stateless)
    * O Backend **nÃ£o armazena** e **nÃ£o busca** histÃ³rico em nenhum banco de dados
    * *IdentificaÃ§Ã£o (`x-user-id`):* O Front gera um UUID apenas para correlacionar logs/analytics. O backend **nÃ£o usa esse ID para buscar dados** (nÃ£o hÃ¡ dados armazenados para buscar!), apenas para logging/tracking. Ã‰ como um "nÃºmero de protocolo" - serve para rastrear requisiÃ§Ãµes nos logs, nÃ£o para recuperar histÃ³rico. Cada request Ã© independente e autocontido.

**Por que Frontend-Driven?**
- âœ… **Simples:** Sem infraestrutura extra (Redis, DynamoDB, etc)
- âœ… **EscalÃ¡vel:** Lambda Ã© stateless, mÃºltiplos usuÃ¡rios nÃ£o se interferem
- âœ… **Privado:** UsuÃ¡rio controla seus dados (localStorage local)
- âœ… **EconÃ´mico:** Zero custo de persistÃªncia para MVP
- âŒ NÃ£o persiste apÃ³s limpar dados do navegador (mas Ã© MVP)

### 2.2. ComunicaÃ§Ã£o: WebSockets vs. HTTP Streaming
* **DÃºvida Levantada:** *"Como fazer a conexÃ£o cliente servidor para esse projeto sabendo do lambda (sobe e morre)? Preciso de WebSockets? Http padrÃ£o resolve? Lambda suporta Streaming de respostas?"*
* **AnÃ¡lise:**
    * *WebSockets:* Em arquitetura Serverless, exigem API Gateway V2 e gerenciamento manual de conexÃµes (`@connections`) no DynamoDB. Muito complexo para uma via de mÃ£o Ãºnica (Bot respondendo)
    * *API Gateway PadrÃ£o:* Faz buffer da resposta (espera tudo ficar pronto para enviar), matando o efeito de digitaÃ§Ã£o
* **DecisÃ£o Final:** **Lambda Function URL com Response Streaming**
    * Usaremos o modo `RESPONSE_STREAM` nativo da Lambda
    * Isso permite enviar chunks de texto via HTTP padrÃ£o assim que o LangChain os gera

### 2.3. Framework Backend: Nuxt Nitro vs. Express.js
* **DÃºvida Levantada:** *"Por que usar Nitro? Existem outras alternativas como Express?"*
* **AnÃ¡lise:**
    * *Express:* Pesado, lento para iniciar (*cold start*) e nÃ£o otimizado para Serverless moderno
    * *Nitro:* Ã‰ o motor nativo do Nuxt. Permite escrever a API dentro da mesma pasta do projeto Frontend, compartilha a configuraÃ§Ã£o de build e compila para um pacote minÃºsculo otimizado para Lambda
* **DecisÃ£o Final:** **Nuxt Nitro**. Pela simplicidade de manter um Ãºnico repositÃ³rio (Monorepo implÃ­cito) e performance

### 2.4. EstratÃ©gia de RAG: Vetorial vs. Contexto Bruto
* **DÃºvida Levantada:** *"Por que um banco vetorial? Por que nÃ£o extrair o JSON do texto e jogar no prompt?"*
* **AnÃ¡lise:**
    * *Contexto Bruto:* Jogar um PDF inteiro no prompt estoura o limite de tokens do modelo e custa caro
* **DecisÃ£o Final:** **Qdrant (Vetorial)**
    * Usaremos o LangChain para dividir o PDF em pedaÃ§os
    * O Qdrant busca semanticamente apenas os trechos relevantes Ã  pergunta
    * A IA recebe apenas o necessÃ¡rio para responder

### 2.5. OrquestraÃ§Ã£o: LangChain vs. "Na MÃ£o"
* **DÃºvida Levantada:** *"Vamos usar LangChain ou chamar a OpenAI direto? LangChain nÃ£o Ã© complexo para streaming?"*
* **AnÃ¡lise:**
    * O LangChain antigo era complexo. O novo (LCEL - LangChain Expression Language) simplificou o streaming com o mÃ©todo `.stream()`
    * Fazer a ingestÃ£o do PDF (Splitters + Embeddings) "na mÃ£o" Ã© muito trabalhoso
* **DecisÃ£o Final:** **HÃ­brido/LangChain**
    * Usaremos LangChain para processar o PDF
    * Usaremos LangChain para o Chat, aproveitando a integraÃ§Ã£o nativa de streaming

---

### 2.6. Resumo das DecisÃµes TÃ©cnicas

| Item | DÃºvida/Contexto | Onde estÃ¡ documentado | SoluÃ§Ã£o Adotada |
|------|----------------|----------------------|-----------------|
| **Redis (Inicialmente)** | "Devo usar Redis para o histÃ³rico? Posso usar variÃ¡vel global em Python/Node? O Qdrant salva o histÃ³rico? Banco nÃ£o relacional / relacional funciona aqui?" | **SeÃ§Ã£o 2.1** | Descartado por custo/complexidade (VPC). Usamos LocalStorage no frontend. |
| **IdentificaÃ§Ã£o UsuÃ¡rio** | Como identificar usuÃ¡rios sem autenticaÃ§Ã£o? | **SeÃ§Ã£o 2.1** | UUID no LocalStorage para logs/analytics. Enviado via header `x-user-id`. |
| **Banco Vetorial vs. Relacional** | "Por que um banco vetorial? Por que nÃ£o extrair o JSON do texto e jogar no prompt?" | **SeÃ§Ã£o 2.4** | Qdrant resolve o problema de Context Window (limite de tokens). Busca semÃ¢ntica. |
| **WebSocket vs. Lambda** | Como fazer conexÃ£o cliente-servidor sabendo que Lambda sobe e morre? WebSockets ou HTTP resolve? | **SeÃ§Ã£o 2.2** | WebSocket complexo demais. Usamos HTTP Streaming com `RESPONSE_STREAM`. |
| **LangChain vs. Na mÃ£o** | "Vamos usar LangChain ou chamar a OpenAI direto? LangChain nÃ£o Ã© complexo para streaming?" | **SeÃ§Ã£o 2.5** | Sim. Nova sintaxe (`.stream()`) simplificou. Processa PDF automaticamente. |
| **MemÃ³ria Persistente** | Onde salvar o histÃ³rico? | **SeÃ§Ã£o 2.1** | Frontend Ã© o "dono" do estado. Envia histÃ³rico completo a cada request. |
| **Config AWS Lambda (Streaming)** | Como ativar streaming na Lambda? | **SeÃ§Ã£o 5.1** | `invokeMode: RESPONSE_STREAM` no `serverless.yml`. |
| **Nuxt Nitro vs. Express** | Por que Nitro e nÃ£o Express? | **SeÃ§Ã£o 2.3** | Nitro Ã© nativo do Nuxt, evita cold start, monorepo simplificado. |
| **Function URL vs. API Gateway** | Qual usar para evitar buffer? | **SeÃ§Ã£o 1** | Function URL direto, sem passar pelo API Gateway tradicional. |
| **PDF Processing** | pdf-parse ou LangChain? | **Package.json** | 100% LangChain com `PDFLoader`. Mais integrado e sem deps extras. |
| **Upload de PDF** | Script local ou interface web? | **SeÃ§Ã£o 5.1.1** | Interface web com drag & drop. Endpoint `/api/ingest` processa upload. |

---

### 2.7. Arquitetura Serverless: Nuxt Full-Stack vs. Node.js + Vue Separados

#### ğŸ¯ A DecisÃ£o: Por que Nuxt MonolÃ­tico para MVP?

Este projeto usa **Nuxt Full-Stack** (Frontend + Backend no mesmo Lambda). Mas por quÃª? E como seria com separaÃ§Ã£o tradicional?

#### ğŸ“¦ Nuxt Full-Stack (Atual)

**Estrutura:**
```
Seu Projeto
â”œâ”€â”€ pages/          â† Frontend (Vue components renderizados)
â”œâ”€â”€ server/         â† Backend (Node.js/H3 endpoints)
â””â”€â”€ nuxt.config.ts  â† ConfiguraÃ§Ã£o Ãºnica
```

**Build & Deploy:**
```
npm run build
         â†“
    .output/
    â”œâ”€â”€ public/      â† Assets estÃ¡ticos (JS, CSS)
    â”œâ”€â”€ server/      â† Node.js compilado
    â””â”€â”€ index.mjs    â† Entry point Ãºnico
         â†“
    Upload para AWS Lambda (Ãºnico pacote)
```

**Em ExecuÃ§Ã£o (Lambda):**
```
Usuario acessa: https://api.lambda.amazonaws.com/
                         â†“
                    Lambda Function
                    (index.mjs inicia)
                         â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â†“                             â†“
    GET /            GET /api/chat
  (Renderiza HTML)  (LangChain + RAG)
   (Frontend Vue)    (Backend Node.js)
```

**Vantagens para MVP:**
- âœ… **CÃ³digo compartilhado**: Types, utilities, validaÃ§Ãµes entre frontend e backend
- âœ… **Uma Ãºnica build**: Simplifica CI/CD
- âœ… **Deploy simples**: Um arquivo ZIP para Lambda
- âœ… **SSR/Rendering**: Nuxt renderiza HTML no servidor (melhora SEO, primeira carga mais rÃ¡pida)
- âœ… **Monorepo implÃ­cito**: Sem necessidade de gerenciar mÃºltiplos repos

**Desvantagens:**
- âŒ **Cold starts maiores**: Bundle = LangChain (~5MB) + Vue (~500KB) + Qdrant (~10MB) = 15-30MB zipped
  - Resultado: 10-30 segundos no primeiro request â±ï¸
- âŒ **Limite de tamanho**: Lambda tem limite de 50MB (zipped), vocÃª fica perto do limite
- âŒ **Scaling desacoplado impossÃ­vel**: Frontend e backend escalam juntos (nÃ£o ideal em produÃ§Ã£o)

---

#### ğŸ—ï¸ Node.js + Vue Separados (ProduÃ§Ã£o)

**Arquitetura Desacoplada:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 + CDN      â”‚         â”‚   Lambda     â”‚
â”‚  (Vue Build)    â”‚         â”‚  (Node API)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
    estÃ¡ticos.com          api.estÃ¡ticos.com
      (S3+CF)               (API puro)
```

**Build Diferenciado:**
```bash
# Frontend: Build estÃ¡tico
npm run build:frontend
    â†“
dist/
â”œâ”€â”€ index.html
â”œâ”€â”€ js/
â”œâ”€â”€ css/
â””â”€â”€ assets/
    â†“
Upload para S3 â†’ CloudFront (CDN)

# Backend: API isolada
npm run build:api
    â†“
.output-api/
â”œâ”€â”€ server/
â””â”€â”€ index.mjs
    â†“
Upload para Lambda
```

**Em ExecuÃ§Ã£o:**
```
Usuario acessa: https://estÃ¡ticos.com
                      â†“
    CloudFront serve HTML/JS/CSS
    (Assets estÃ¡ticos prÃ©-compilados)
                      â†“
   Script Vue executa no navegador
                      â†“
   POST /api/chat â†’ https://api.estÃ¡ticos.com
                      â†“
              Lambda Function
          (Node.js + LangChain puro)
                      â†“
         Retorna resposta com streaming
```

**Vantagens para ProduÃ§Ã£o:**
- âœ… **Cold starts reduzidos**: Lambda contÃ©m apenas LangChain (~15MB) + dependÃªncias
  - Resultado: 3-5 segundos no primeiro request
- âœ… **Scaling independente**: Se frontend Ã© acessado muito, CDN absorve. Se backend Ã© pesado, Lambda escala Ã  parte
- âœ… **Cache agressivo**: S3 + CloudFront cacheia assets por anos
- âœ… **Assets globais**: CDN distribui JS/CSS pelo mundo
- âœ… **SeparaÃ§Ã£o de responsabilidades**: Frontend versionado separado do backend

**Desvantagens:**
- âŒ **Complexidade aumenta**: Gerenciar 2 builds, 2 deployments, 2 repos
- âŒ **Setup inicial**: Precisa configurar CloudFront, S3, origem do CORS
- âŒ **Custo**: S3 + CloudFront adiciona custo (porÃ©m mÃ­nimo para MVP)

---

#### ğŸ“Š ComparaÃ§Ã£o Lado a Lado

| Aspecto | Nuxt Full-Stack (Atual) | Node + Vue Separados |
|--------|-------------------------|----------------------|
| **Cold Start** | 10-30s | 3-5s |
| **Tamanho Bundle** | 20-30MB | 15MB (API) + 2MB (Frontend) |
| **Complexidade** | Baixa | MÃ©dia |
| **Deploy** | Um comando | Dois comandos (2 pipelines) |
| **Cache Frontend** | Nenhum (sempre do Lambda) | Agressivo (CDN) |
| **Custo Mensal** | ~$0.20 (poucos reqs) | ~$1-3 (inclui CDN) |
| **Escalabilidade** | Ruim | Excelente |
| **Recomendado para** | MVP, protÃ³tipos | ProduÃ§Ã£o, alto trÃ¡fego |

---

#### ğŸ¬ Roadmap Sugerido

1. **Fase 1 (MVP - Atual)**: Nuxt Full-Stack
   - VÃ¡lido para <100 reqs/dia
   - Prototipa rÃ¡pido
   - Deploy simples

2. **Fase 2 (Beta - ~1 mÃªs)**: SeparaÃ§Ã£o de builds
   - MantÃ©m monorepo Ãºnico
   - Scripts `build:frontend` e `build:api`
   - Deployments independentes mas no mesmo repo

3. **Fase 3 (ProduÃ§Ã£o)**: Monorepo split
   - 2 repositÃ³rios (`frontend` e `backend-api`)
   - CI/CD pipelines completamente separadas
   - Scaling independente

---

#### ğŸ’¡ Resposta TÃ©cnica: Como Funciona?

**Por que ambos vÃ£o juntos para Lambda atualmente?**

Quando vocÃª executa `npm run build` no Nuxt:

1. Nuxt compila o Vue em componentes reativos
2. Nuxt compila o `/server` em mÃ³dulos Node.js
3. Tudo Ã© empacotado em `.output/` com um Ãºnico `index.mjs`
4. VocÃª faz zip de `.output/` e upload para Lambda
5. Lambda executa `index.mjs`, que:
   - Inicia um servidor Node.js na porta 3000
   - Quando recebe GET `/`, renderiza HTML do Vue
   - Quando recebe POST `/api/chat`, executa o handler do server

**Resultado**: Uma Ãºnica funÃ§Ã£o Lambda atende ambos.

**Vantagem futura**: VocÃª pode exportar apenas o `/server` compilado para uma Lambda separada sem alterar cÃ³digo (apenas CI/CD).


## 3. Fluxo de Trabalho Git (PadrÃ£o Standard)

Seguiremos rigorosamente este fluxo para organizaÃ§Ã£o.

### Regras de Branch
1. **Nunca** commitar na `main` ou `develop` diretamente
2. Toda branch nasce da `develop`
3. Toda branch morre (merge) na `develop`

### Nomenclatura
PadrÃ£o: `DDMMYY-Feature-Description`

#### Formato
- **DDMMYY**: Data no formato dia/mÃªs/ano (2 dÃ­gitos cada)
- **Feature**: Nome da feature em kebab-case
- **Description**: DescriÃ§Ã£o adicional em kebab-case

#### Exemplos
041125-DB-schemas-review-refactor
031225-Notifications-V2-implementation
031225-Alerts-refactor-remove-airlines
031225-Redis-optimization-monthly-quotas
031225-Moblix-V2-integration
#### Regras
- Use kebab-case (palavras separadas por hÃ­fens)
- Seja descritivo mas conciso
- Inclua a data de criaÃ§Ã£o da branch
- Use maiÃºsculas apenas para siglas (V2, API, DB)

### Fluxo Simplificado

#### Estrutura
```
Feature Branch â†’ develop â†’ master
```

#### Fluxo Detalhado

1. **Criar branch de feature**
   ```bash
   git checkout develop
   git pull origin develop
   git checkout -b 081225-project-setup
   ```

2. **Desenvolver feature**
   - MÃºltiplos commits organizados
   - Commits seguindo Conventional Commits
   - Data jÃ¡ estÃ¡ no nome da branch (nÃ£o repetir nos commits)

3. **Criar Pull Request**
   - PR: `081225-project-setup` â†’ `develop`
   - Adicionar descriÃ§Ã£o clara
   - Linkar issues relacionadas

4. **Merge em develop**
   - ApÃ³s code review e aprovaÃ§Ã£o
   - Testes passando
   - Sem conflitos
   - Merges frequente na branch develop

5. **Merge em master**
   - Apenas quando funÃ§Ã£o de alto nÃ­vel estiver completa
   - Testes passando
   - DocumentaÃ§Ã£o atualizada
   - CoordenaÃ§Ã£o com frontend alinhada

### Regra: Sempre Partir de Develop

**Todas as branches de feature devem SEMPRE ser criadas a partir de `develop`.**

#### Por quÃª?

1. **`develop` Ã© a branch de integraÃ§Ã£o estÃ¡vel**
   - ContÃ©m todas as features jÃ¡ mergeadas e testadas
   - Ã‰ o ponto de referÃªncia comum para todo o time

2. **Evita dependÃªncias entre features**
   - Cada feature Ã© independente
   - NÃ£o cria dependÃªncias desnecessÃ¡rias entre branches

3. **Facilita o merge posterior**
   - Menos conflitos ao fazer merge em `develop`
   - HistÃ³rico mais limpo e organizado

4. **MantÃ©m todas as features no mesmo ponto de partida**
   - Garante consistÃªncia entre diferentes features
   - Facilita code review e testes

#### Workflow Correto

```bash
# 1. SEMPRE voltar para develop primeiro
git checkout develop

# 2. Atualizar develop com o remoto (importante!)
git pull origin develop

# 3. Criar nova branch de feature a partir de develop atualizada
git checkout -b 081225-project-setup

# 4. Agora trabalhar na feature
git add <arquivos>
git commit -m "feat(setup): ..."
```

#### O Que NÃƒO Fazer

```bash
# âŒ ERRADO - Criar branch a partir de outra feature branch
git checkout 091225-backend-logic
git checkout -b 101225-frontend-ui  # ERRADO!

# âŒ ERRADO - Criar branch sem atualizar develop primeiro
git checkout develop
git checkout -b 081225-project-setup  # Pode estar desatualizada!
```

### PrincÃ­pios
- **Features**: Merge direto em `develop` via PR
- **Master**: Merge apenas quando funÃ§Ã£o completa e testada
- **Develop**: Sempre estÃ¡vel para basear trabalho

### Conventional Commits

#### Formato
```
<tipo>(<escopo>): <descriÃ§Ã£o>
```

#### Tipos Comuns
- `feat`: Nova funcionalidade
- `fix`: CorreÃ§Ã£o de bug
- `docs`: DocumentaÃ§Ã£o
- `style`: FormataÃ§Ã£o (sem mudanÃ§a de cÃ³digo)
- `refactor`: RefatoraÃ§Ã£o
- `perf`: Melhoria de performance
- `test`: Testes
- `chore`: Tarefas de manutenÃ§Ã£o
- `ci`: CI/CD
- `build`: Build system

#### Exemplos
```bash
feat(auth): adiciona login com Google OAuth
fix(payment): corrige cÃ¡lculo de desconto
docs(readme): atualiza instruÃ§Ãµes de instalaÃ§Ã£o
refactor(api): simplifica validaÃ§Ã£o de dados
```

#### Primeira Linha
- Use o imperativo: "adiciona", "corrige", "atualiza"
- NÃ£o use: "adicionado", "corrigido", "atualizado"
- Seja especÃ­fico e claro
- Evite mensagens genÃ©ricas como "update" ou "fix"

#### Boas PrÃ¡ticas
- Um commit = uma mudanÃ§a lÃ³gica
- Commits pequenos e frequentes
- Teste antes de commitar
- Use o corpo para explicar o "porquÃª" quando necessÃ¡rio

#### Estrutura Completa

```
<tipo>(<escopo>): <assunto curto>

<corpo opcional explicando o porquÃª>

<rodapÃ© opcional com referÃªncias>
```

#### Exemplo Completo
```bash
feat(api): adiciona endpoint de busca de usuÃ¡rios

Implementa busca paginada com filtros por nome e email.
Isso melhora a performance em listas grandes de usuÃ¡rios.

Closes #123
```

#### Exemplos de Boas Mensagens
```bash
feat(chat): adiciona componente ChatMessage
feat(api): implementa endpoint de streaming
feat(rag): integra Qdrant para busca vetorial
refactor(ui): simplifica lÃ³gica de LocalStorage
fix(stream): corrige encoding de caracteres especiais
docs(readme): atualiza instruÃ§Ãµes de instalaÃ§Ã£o
```

#### Exemplos de Mensagens a Evitar
```bash
# âŒ Evite
update
fix
changes
WIP
test

# âœ… Prefira
feat(chat): adiciona componente ChatMessage
fix(stream): corrige encoding de caracteres especiais
refactor(ui): simplifica lÃ³gica de LocalStorage
```

---

## 4. Roteiro de ImplementaÃ§Ã£o (Roadmap)

Siga esta ordem exata para evitar bloqueios.

### Fase 0: Setup Inicial
* **Branch:** `project-setup`
* **Tarefas:**
    * Init Nuxt 3
    * Install LangChain/OpenAI libs
    * Configurar `.env`

### Fase 1: O "CÃ©rebro" (IngestÃ£o de Dados)
* **Branch:** `rag-ingestion-implementation`
* **Tarefas:**
    * Criar endpoint `server/api/ingest.post.ts`
    * Receber PDF via multipart/form-data
    * Processar com LangChain (`PDFLoader` + `RecursiveCharacterTextSplitter`)
    * Gerar Embeddings e salvar no Qdrant
    * Criar componente `DocumentUpload.vue` (drag & drop)
* *Nota:* O upload agora Ã© feito via interface web, nÃ£o por script local

### Fase 2: O Backend LÃ³gico
* **Branch:** `backend-logic-implementation`
* **Tarefas:**
    * Criar rota Nitro `server/api/chat.post.ts`
    * Receber `{ question, history }`
    * Configurar conexÃ£o Qdrant + OpenAI via LangChain
    * Testar resposta texto simples (sem stream)

### Fase 3: O Frontend Visual
* **Branch:** `frontend-ui-implementation`
* **Tarefas:**
    * Layout do Chat
    * LÃ³gica de `LocalStorage` (Salvar histÃ³rico)
    * Envio do Payload completo para a API

### Fase 4: O Streaming (IntegraÃ§Ã£o Final)
* **Branch:** `streaming-implementation`
* **Tarefas:**
    * **Back:** Mudar resposta para `sendStream` com iterÃ¡vel do LangChain
    * **Front:** Mudar `fetch` para usar `getReader()` e montar texto em tempo real
    * **Infra:** Configurar `serverless.yml` com `invokeMode: RESPONSE_STREAM`

---

## 5. ImplementaÃ§Ã£o TÃ©cnica de ReferÃªncia

### 5.1 Endpoints da API

O projeto possui **2 endpoints principais**:

#### 5.1.1 `/api/ingest` - Upload de Documentos

Endpoint para fazer upload de PDFs e processar para o Qdrant.

**Request:**
```http
POST /api/ingest
Content-Type: multipart/form-data

file: <PDF_FILE>
```

**Response:**
Retorna JSON com status de sucesso, nÃºmero de chunks processados e ID do documento.

**Detalhes de ImplementaÃ§Ã£o:**
Ver cÃ³digo em `server/api/ingest.post.ts` para implementaÃ§Ã£o completa com PDFLoader, RecursiveCharacterTextSplitter e integraÃ§Ã£o Qdrant.

#### 5.1.2 `/api/chat` - ConversaÃ§Ã£o com Streaming

Endpoint para conversar com o chatbot. Retorna resposta via streaming.

**Request:**
```http
POST /api/chat
Content-Type: application/json
x-user-id: <UUID>

{
  "question": "Qual Ã© o conteÃºdo do documento?",
  "history": [
    { "role": "user", "content": "Pergunta anterior" },
    { "role": "assistant", "content": "Resposta anterior" }
  ]
}
```

**Response:**
```http
Content-Type: text/event-stream

[Streaming de texto em tempo real]
```

**ImplementaÃ§Ã£o:** Ver seÃ§Ã£o 5.2

### 5.2 Arquivo de ConfiguraÃ§Ã£o (`serverless.yml`)

ConfiguraÃ§Ã£o vital para o streaming funcionar na AWS.

**Pontos Principais:**
- `invokeMode: RESPONSE_STREAM` - Essencial para streaming funcionar
- `timeout: 30` - Timeout de 30 segundos para processar requisiÃ§Ãµes
- `memorySize: 512` - MemÃ³ria RAM alocada para a Lambda
- VariÃ¡veis de ambiente carregadas via `serverless-dotenv-plugin`

### 5.3 LÃ³gica de Streaming no Nitro (`server/api/chat.post.ts`)

**Fluxo de Streaming:**
1. Recebe `{ question, history }` do frontend
2. Transforma histÃ³rico JSON em objetos LangChain (HumanMessage, AIMessage)
3. Configura ChatOpenAI com `streaming: true`
4. Cria Chain com prompt template + LLM + output parser
5. Configura headers HTTP (`Content-Type: text/event-stream`)
6. Executa chain e converte para ReadableStream
7. Retorna stream usando `sendStream(event, readable)`

**Ver implementaÃ§Ã£o completa em:** `server/api/chat.post.ts`

### 5.4 Guia de ImplementaÃ§Ã£o AWS Serverless (Credenciais + Deploy)

**Resumo direto**
- **Para que servem as chaves (Access Key / Secret):** credenciais de usuÃ¡rio IAM para o CLI (Serverless Framework / AWS CLI) autenticar na sua conta AWS e criar/atualizar recursos. Sem elas, o `serverless deploy` nÃ£o tem permissÃ£o para subir nada.
- **Quem usa:** o prÃ³prio `serverless deploy` (via AWS SDK) e qualquer comando AWS CLI. NÃ£o sÃ£o usadas pelo cÃ³digo do app em runtime e nÃ£o vÃ£o dentro do bundle.
- **Onde ficam:** o comando `serverless config credentials --provider aws --key ... --secret ...` salva em `~/.aws/credentials` (e `~/.aws/config`), fora do projeto e fora do Git.
- **RelaÃ§Ã£o com `serverless.yml`:**
  - O `serverless.yml` descreve o que criar na AWS: serviÃ§o `rag-chatbot-mvp`, runtime `nodejs18.x`, regiÃ£o `us-east-1`, funÃ§Ã£o `api` apontando para `.output/server/index.handler`, URL pÃºblica com CORS e streaming, timeout/memÃ³ria e variÃ¡veis de ambiente do Lambda.
  - Ao rodar `serverless deploy`, o Serverless Framework lÃª o `serverless.yml`, empacota o handler e usa as credenciais do `~/.aws/credentials` para provisionar/atualizar a Lambda + URL.
  - As variÃ¡veis em `environment:` (`OPENAI_API_KEY`, `QDRANT_URL`, etc.) sÃ£o injetadas no runtime da Lambda a partir do ambiente do deploy (via `.env` + `serverless-dotenv-plugin` ou variÃ¡veis do CI). **NÃ£o** devem conter as chaves IAM; essas ficam sÃ³ no perfil local/CI para autenticaÃ§Ã£o do deploy.

**Resumo prÃ¡tico**
1) Guarde as chaves IAM apenas em `~/.aws/credentials` (ou variÃ¡veis de ambiente no CI).
2) Coloque apenas as variÃ¡veis do app em `.env` (OpenAI/Qdrant etc.).
3) Rode `pnpm build` para gerar `.output/server/index.handler`.
4) Rode `serverless deploy`: ele usa as credenciais locais para falar com a AWS e criar/atualizar a Lambda conforme o `serverless.yml`.

#### ğŸ“Œ Guia passo a passo (AWS + Serverless)

##### Fase 1: O Terreno (AWS Root)
Objetivo: ter uma conta ativa na nuvem.
1. Acessar `aws.amazon.com` e criar a conta (root user) com email, pagamento e verificaÃ§Ã£o.

##### Fase 2: O CrachÃ¡ do RobÃ´ (IAM User)
Objetivo: gerar chaves para o Serverless Framework atuar na conta.
1. No console AWS, abrir **IAM > Users > Create User** (ex: `serverless-admin`).
2. Em **Permissions**, usar **Attach policies directly** â†’ `AdministratorAccess` (para facilitar o MVP).
3. Abrir o usuÃ¡rio criado â†’ aba **Security Credentials** â†’ **Access Keys** â†’ **Create access key** â†’ opÃ§Ã£o **Command Line Interface (CLI)**.
4. Copiar `Access Key ID` e `Secret Access Key` (guardar em local seguro).

##### Fase 3: Configurar o "crachÃ¡" no Serverless Framework
Objetivo: instalar a ferramenta e armazenar as credenciais localmente.
```bash
npm install -g serverless
serverless config credentials --provider aws --key SUA_ACCESS_KEY --secret SUA_SECRET_KEY
```
*Esse comando salva em `~/.aws/credentials` para o Serverless usar sempre. NÃ£o vai para o repo.*

##### Fase 4: Preparar o Projeto Nuxt
Objetivo: deixar o cÃ³digo pronto para empacotar.
```bash
pnpm add -D serverless-dotenv-plugin

# Criar .env na raiz (exemplo)
OPENAI_API_KEY=sk-proj-...
QDRANT_URL=https://...
QDRANT_API_KEY=th-...

# Conferir serverless.yml (resumo)
service: rag-chatbot-mvp
frameworkVersion: '3'
provider:
  name: aws
  runtime: nodejs18.x
  region: us-east-1
  environment:
    OPENAI_API_KEY: ${env:OPENAI_API_KEY}
    QDRANT_URL: ${env:QDRANT_URL}
    QDRANT_API_KEY: ${env:QDRANT_API_KEY}
functions:
  api:
    handler: .output/server/index.handler
    url:
      cors: true
      invokeMode: RESPONSE_STREAM
    timeout: 30
plugins:
  - serverless-dotenv-plugin
```

##### Fase 5: Build e Deploy
Objetivo: compilar o Nuxt e enviar para a AWS.
```bash
pnpm build          # gera .output
serverless deploy   # lÃª o serverless.yml e faz o upload
```
ApÃ³s o deploy, o terminal retorna a Function URL pÃºblica (ex: `https://xyz.lambda-url.us-east-1.on.aws`).

## 6. Estrutura do Projeto

```
Serverless-RAG-Chatbot-MVP-/
â”œâ”€â”€ .env.example                 # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                   # Arquivos ignorados pelo Git
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ package.json                 # DependÃªncias do projeto
â”œâ”€â”€ nuxt.config.ts               # ConfiguraÃ§Ã£o do Nuxt 3
â”œâ”€â”€ tsconfig.json                # ConfiguraÃ§Ã£o do TypeScript
â”œâ”€â”€ tailwind.config.js           # ConfiguraÃ§Ã£o do Tailwind CSS
â”œâ”€â”€ serverless.yml               # ConfiguraÃ§Ã£o de deploy AWS Lambda
â”‚
â”œâ”€â”€ app.vue                      # Componente raiz da aplicaÃ§Ã£o
â”œâ”€â”€ pages/                       # PÃ¡ginas da aplicaÃ§Ã£o
â”‚   â””â”€â”€ index.vue                # PÃ¡gina inicial (Chat UI)
â”‚
â”œâ”€â”€ components/                  # Componentes Vue reutilizÃ¡veis
â”‚   â”œâ”€â”€ ChatMessage.vue          # Componente de mensagem individual
â”‚   â”œâ”€â”€ ChatInput.vue            # Componente de input de mensagem
â”‚   â”œâ”€â”€ ChatWindow.vue           # Componente da janela de chat
â”‚   â”œâ”€â”€ ThemeToggle.vue          # Toggle de dark mode
â”‚   â””â”€â”€ DocumentUpload.vue       # Upload de PDF (drag & drop)
â”‚
â”œâ”€â”€ composables/                 # Composables Vue (lÃ³gica reutilizÃ¡vel)
â”‚   â”œâ”€â”€ useChatHistory.ts        # Gerenciamento do histÃ³rico no LocalStorage
â”‚   â””â”€â”€ useChatStream.ts         # LÃ³gica de streaming de mensagens
â”‚
â”œâ”€â”€ server/                      # Backend Nitro
â”‚   â”œâ”€â”€ api/                     # Rotas da API
â”‚   â”‚   â”œâ”€â”€ chat.post.ts         # Endpoint de conversaÃ§Ã£o (streaming)
â”‚   â”‚   â””â”€â”€ ingest.post.ts       # Endpoint de upload de PDF
â”‚   â”œâ”€â”€ utils/                   # UtilitÃ¡rios do servidor
â”‚   â”‚   â”œâ”€â”€ langchain.ts         # ConfiguraÃ§Ã£o do LangChain
â”‚   â”‚   â””â”€â”€ qdrant.ts            # ConfiguraÃ§Ã£o do Qdrant
â”‚   â””â”€â”€ middleware/              # Middleware do servidor
â”‚
â”œâ”€â”€ scripts/                     # Scripts auxiliares
â”‚   â”œâ”€â”€ ingest.ts                # Script de ingestÃ£o de PDF para Qdrant
â”‚   â””â”€â”€ README.md                # DocumentaÃ§Ã£o dos scripts
â”‚
â”œâ”€â”€ data/                        # Dados do projeto
â”‚   â””â”€â”€ documents/               # PDFs para ingestÃ£o
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ public/                      # Arquivos estÃ¡ticos
â”‚   â””â”€â”€ favicon.ico
â”‚
â””â”€â”€ assets/                      # Assets processados (CSS, imagens)
    â””â”€â”€ css/
        â””â”€â”€ main.css             # CSS global
```
