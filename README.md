# ğŸ“˜ DocumentaÃ§Ã£o: Serverless RAG Chatbot (MVP)

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral e Stack TecnolÃ³gico](#1-visÃ£o-geral-e-stack-tecnolÃ³gico)
2. [Registro de DecisÃµes e DÃºvidas](#2-registro-de-decisÃµes-e-dÃºvidas-architecture-decision-record)
3. [Fluxo de Trabalho Git](#3-fluxo-de-trabalho-git-padrÃ£o-promiles)
4. [Roteiro de ImplementaÃ§Ã£o](#4-roteiro-de-implementaÃ§Ã£o-roadmap)
5. [ImplementaÃ§Ã£o TÃ©cnica de ReferÃªncia](#5-implementaÃ§Ã£o-tÃ©cnica-de-referÃªncia)
6. [OtimizaÃ§Ã£o de Bundle: API-Only vs Full-Stack](#6-ğŸ“¦-otimizaÃ§Ã£o-de-bundle-api-only-vs-full-stack)
7. [Estrutura do Projeto](#7-estrutura-do-projeto)
8. [Como ComeÃ§ar](#8-como-comeÃ§ar)

---

## 1. VisÃ£o Geral e Stack TecnolÃ³gico

O objetivo Ã© criar um Chatbot de InteligÃªncia Artificial que responda perguntas baseadas em um documento PDF privado (RAG), com interface reativa e respostas via streaming.

### Frontend (AplicaÃ§Ã£o Web)
* **Framework:** **Nuxt 3** (Vue.js + TailwindCSS)
* **Gerenciamento de SessÃ£o:** **LocalStorage** (Navegador do Cliente)
* **ComunicaÃ§Ã£o:** `fetch` nativo com leitura de `ReadableStream`

### Backend (Serverless API)
* **Framework:** **Nuxt Nitro** (Server Routes - `/server/api`)
* **Runtime:** Node.js rodando em **AWS Lambda**
* **Acesso:** **Function URL** (Endpoint HTTPS direto, sem API Gateway complexo)
* **Streaming:** `InvokeMode: RESPONSE_STREAM`
* **Endpoints:**
    * `/api/ingest` - Upload e processamento de PDFs 
    * `/api/chat` - ConversaÃ§Ã£o com o chatbot (streaming de resposta)

### InteligÃªncia & Dados
* **LLM:** OpenAI `gpt-5-nano`
* **OrquestraÃ§Ã£o:** **LangChain.js** (Core & Community)
* **Banco de Conhecimento:** **Qdrant** (Vector Database)
    * *FunÃ§Ã£o:* Armazenar o PDF (chunks) e transformado em vetores

---

## 2. ğŸ§  Registro de DecisÃµes e DÃºvidas (Architecture Decision Record)

Esta seÃ§Ã£o detalha as dÃºvidas levantadas durante o planejamento e a soluÃ§Ã£o final adotada.

### 2.1. MemÃ³ria do Chat: Redis vs. LocalStorage vs. In-Memory
* **DÃºvida Levantada:** *"Devo usar Redis para o histÃ³rico? Posso usar variÃ¡vel global em Python/Node? O Qdrant salva o histÃ³rico? Banco nÃ£o relacional / relacional funciona aqui?"*
* **AnÃ¡lise:**
    * *Qdrant:* NÃ£o serve para histÃ³rico de conversa, serve apenas para conhecimento (PDF)
    * *In-Memory (variÃ¡vel global):* ImpossÃ­vel em AWS Lambda, pois a funÃ§Ã£o "morre" apÃ³s o uso (Stateless). VariÃ¡vel global Node seria perdida entre invocaÃ§Ãµes
    * *Banco Relacional (PostgreSQL, MySQL):* Funcionaria tecnicamente, mas Ã© "overkill" para MVP. Exige RDS (custo), gerenciamento de conexÃµes e esquema de dados
    * *Banco NÃ£o Relacional (DynamoDB, MongoDB):* TambÃ©m funcionaria, mas adiciona complexidade de queries e custo. DynamoDB seria serverless, mas precisa gerenciar TTL e cleanup
    * *Redis:* Seria a soluÃ§Ã£o robusta padrÃ£o para cache de sessÃ£o, mas adiciona custo (instÃ¢ncia paga) e complexidade de infraestrutura (VPC) desnecessÃ¡ria para um MVP
* **DecisÃ£o Final:** **Frontend-Driven History**
    * O Frontend guarda o array de mensagens no LocalStorage
    * A cada nova pergunta, o Frontend envia o **histÃ³rico completo** no `body` da requisiÃ§Ã£o
    * O Backend recebe tudo que precisa no request, processa e responde (stateless)
    * O Backend **nÃ£o armazena** e **nÃ£o busca** histÃ³rico em nenhum banco de dados
    * *IdentificaÃ§Ã£o (`x-user-id`):* O Front gera um UUID apenas para correlacionar logs/analytics. O backend **nÃ£o usa esse ID para buscar dados** (nÃ£o hÃ¡ dados armazenados para buscar!), apenas para logging/tracking. Ã‰ como um "nÃºmero de protocolo" - serve para rastrear requisiÃ§Ãµes nos logs, nÃ£o para recuperar histÃ³rico. Cada request Ã© independente e autocontido.

**Por que Frontend-Driven?**
- âœ… **Simples:** Sem infraestrutura extra (Redis, DynamoDB, etc)
- âœ… **EscalÃ¡vel:** Lambda Ã© stateless, mÃºltiplos usuÃ¡rios nÃ£o se interferem
- âœ… **Privado:** UsuÃ¡rio controla seus dados (localStorage local)
- âœ… **EconÃ´mico:** Zero custo de persistÃªncia para MVP
- âŒ NÃ£o persiste apÃ³s limpar dados do navegador (mas Ã© MVP)

### 2.2. ComunicaÃ§Ã£o: WebSockets vs. HTTP Streaming
* **DÃºvida Levantada:** *"Como fazer a conexÃ£o cliente servidor para esse projeto sabendo do lambda (sobe e morre)? Preciso de WebSockets? Http padrÃ£o resolve? Lambda suporta Streaming de respostas?"*
* **AnÃ¡lise:**
    * *WebSockets:* Em arquitetura Serverless, exigem API Gateway V2 e gerenciamento manual de conexÃµes (`@connections`) no DynamoDB. Muito complexo para uma via de mÃ£o Ãºnica (Bot respondendo)
    * *API Gateway PadrÃ£o:* Faz buffer da resposta (espera tudo ficar pronto para enviar), matando o efeito de digitaÃ§Ã£o
* **DecisÃ£o Final:** **Lambda Function URL com Response Streaming**
    * Usaremos o modo `RESPONSE_STREAM` nativo da Lambda
    * Isso permite enviar chunks de texto via HTTP padrÃ£o assim que o LangChain os gera

### 2.3. Framework Backend: Nuxt Nitro vs. Express.js
* **DÃºvida Levantada:** *"Por que usar Nitro? Existem outras alternativas como Express?"*
* **AnÃ¡lise:**
    * *Express:* Pesado, lento para iniciar (*cold start*) e nÃ£o otimizado para Serverless moderno
    * *Nitro:* Ã‰ o motor nativo do Nuxt. Permite escrever a API dentro da mesma pasta do projeto Frontend, compartilha a configuraÃ§Ã£o de build e compila para um pacote minÃºsculo otimizado para Lambda
* **DecisÃ£o Final:** **Nuxt Nitro**. Pela simplicidade de manter um Ãºnico repositÃ³rio (Monorepo implÃ­cito) e performance

### 2.4. EstratÃ©gia de RAG: Vetorial vs. Contexto Bruto
* **DÃºvida Levantada:** *"Por que um banco vetorial? Por que nÃ£o extrair o JSON do texto e jogar no prompt?"*
* **AnÃ¡lise:**
    * *Contexto Bruto:* Jogar um PDF inteiro no prompt estoura o limite de tokens do modelo e custa caro
* **DecisÃ£o Final:** **Qdrant (Vetorial)**
    * Usaremos o LangChain para dividir o PDF em pedaÃ§os
    * O Qdrant busca semanticamente apenas os trechos relevantes Ã  pergunta
    * A IA recebe apenas o necessÃ¡rio para responder

### 2.5. OrquestraÃ§Ã£o: LangChain vs. "Na MÃ£o"
* **DÃºvida Levantada:** *"Vamos usar LangChain ou chamar a OpenAI direto? LangChain nÃ£o Ã© complexo para streaming?"*
* **AnÃ¡lise:**
    * O LangChain antigo era complexo. O novo (LCEL - LangChain Expression Language) simplificou o streaming com o mÃ©todo `.stream()`
    * Fazer a ingestÃ£o do PDF (Splitters + Embeddings) "na mÃ£o" Ã© muito trabalhoso
* **DecisÃ£o Final:** **HÃ­brido/LangChain**
    * Usaremos LangChain para processar o PDF
    * Usaremos LangChain para o Chat, aproveitando a integraÃ§Ã£o nativa de streaming

---

### 2.6. Resumo das DecisÃµes TÃ©cnicas

| Item | DÃºvida/Contexto | Onde estÃ¡ documentado | SoluÃ§Ã£o Adotada |
|------|----------------|----------------------|-----------------|
| **Redis (Inicialmente)** | "Devo usar Redis para o histÃ³rico? Posso usar variÃ¡vel global em Python/Node? O Qdrant salva o histÃ³rico? Banco nÃ£o relacional / relacional funciona aqui?" | **SeÃ§Ã£o 2.1** | Descartado por custo/complexidade (VPC). Usamos LocalStorage no frontend. |
| **IdentificaÃ§Ã£o UsuÃ¡rio** | Como identificar usuÃ¡rios sem autenticaÃ§Ã£o? | **SeÃ§Ã£o 2.1** | UUID no LocalStorage para logs/analytics. Enviado via header `x-user-id`. |
| **Banco Vetorial vs. Relacional** | "Por que um banco vetorial? Por que nÃ£o extrair o JSON do texto e jogar no prompt?" | **SeÃ§Ã£o 2.4** | Qdrant resolve o problema de Context Window (limite de tokens). Busca semÃ¢ntica. |
| **WebSocket vs. Lambda** | Como fazer conexÃ£o cliente-servidor sabendo que Lambda sobe e morre? WebSockets ou HTTP resolve? | **SeÃ§Ã£o 2.2** | WebSocket complexo demais. Usamos HTTP Streaming com `RESPONSE_STREAM`. |
| **LangChain vs. Na mÃ£o** | "Vamos usar LangChain ou chamar a OpenAI direto? LangChain nÃ£o Ã© complexo para streaming?" | **SeÃ§Ã£o 2.5** | Sim. Nova sintaxe (`.stream()`) simplificou. Processa PDF automaticamente. |
| **MemÃ³ria Persistente** | Onde salvar o histÃ³rico? | **SeÃ§Ã£o 2.1** | Frontend Ã© o "dono" do estado. Envia histÃ³rico completo a cada request. |
| **Config AWS Lambda (Streaming)** | Como ativar streaming na Lambda? | **SeÃ§Ã£o 5.1** | `invokeMode: RESPONSE_STREAM` no `serverless.yml`. |
| **Nuxt Nitro vs. Express** | Por que Nitro e nÃ£o Express? | **SeÃ§Ã£o 2.3** | Nitro Ã© nativo do Nuxt, evita cold start, monorepo simplificado. |
| **Function URL vs. API Gateway** | Qual usar para evitar buffer? | **SeÃ§Ã£o 1** | Function URL direto, sem passar pelo API Gateway tradicional. |
| **PDF Processing** | pdf-parse ou LangChain? | **Package.json** | 100% LangChain com `PDFLoader`. Mais integrado e sem deps extras. |
| **Upload de PDF** | Script local ou interface web? | **SeÃ§Ã£o 5.1.1** | Interface web com drag & drop. Endpoint `/api/ingest` processa upload. |

---

### 2.7. Arquitetura Serverless: Nuxt Full-Stack vs. Node.js + Vue Separados

#### ğŸ¯ A DecisÃ£o: Por que Nuxt MonolÃ­tico para MVP?

Este projeto usa **Nuxt Full-Stack** (Frontend + Backend no mesmo Lambda). Mas por quÃª? E como seria com separaÃ§Ã£o tradicional?

#### ğŸ“¦ Nuxt Full-Stack (Atual)

**Estrutura:**
```
Seu Projeto
â”œâ”€â”€ pages/          â† Frontend (Vue components renderizados)
â”œâ”€â”€ server/         â† Backend (Node.js/H3 endpoints)
â””â”€â”€ nuxt.config.ts  â† ConfiguraÃ§Ã£o Ãºnica
```

**Build & Deploy:**
```
npm run build
         â†“
    .output/
    â”œâ”€â”€ public/      â† Assets estÃ¡ticos (JS, CSS)
    â”œâ”€â”€ server/      â† Node.js compilado
    â””â”€â”€ index.mjs    â† Entry point Ãºnico
         â†“
    Upload para AWS Lambda (Ãºnico pacote)
```

**Em ExecuÃ§Ã£o (Lambda):**
```
Usuario acessa: https://api.lambda.amazonaws.com/
                         â†“
                    Lambda Function
                    (index.mjs inicia)
                         â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â†“                             â†“
    GET /            GET /api/chat
  (Renderiza HTML)  (LangChain + RAG)
   (Frontend Vue)    (Backend Node.js)
```

**Vantagens para MVP:**
- âœ… **CÃ³digo compartilhado**: Types, utilities, validaÃ§Ãµes entre frontend e backend
- âœ… **Uma Ãºnica build**: Simplifica CI/CD
- âœ… **Deploy simples**: Um arquivo ZIP para Lambda
- âœ… **SSR/Rendering**: Nuxt renderiza HTML no servidor (melhora SEO, primeira carga mais rÃ¡pida)
- âœ… **Monorepo implÃ­cito**: Sem necessidade de gerenciar mÃºltiplos repos

**Desvantagens:**
- âŒ **Cold starts maiores**: Bundle = LangChain (~5MB) + Vue (~500KB) + Qdrant (~10MB) = 15-30MB zipped
  - Resultado: 10-30 segundos no primeiro request â±ï¸
- âŒ **Limite de tamanho**: Lambda tem limite de 50MB (zipped), vocÃª fica perto do limite
- âŒ **Scaling desacoplado impossÃ­vel**: Frontend e backend escalam juntos (nÃ£o ideal em produÃ§Ã£o)

---

#### ğŸ—ï¸ Node.js + Vue Separados (ProduÃ§Ã£o)

**Arquitetura Desacoplada:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 + CDN      â”‚         â”‚   Lambda     â”‚
â”‚  (Vue Build)    â”‚         â”‚  (Node API)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
    estÃ¡ticos.com          api.estÃ¡ticos.com
      (S3+CF)               (API puro)
```

**Build Diferenciado:**
```bash
# Frontend: Build estÃ¡tico
npm run build:frontend
    â†“
dist/
â”œâ”€â”€ index.html
â”œâ”€â”€ js/
â”œâ”€â”€ css/
â””â”€â”€ assets/
    â†“
Upload para S3 â†’ CloudFront (CDN)

# Backend: API isolada
npm run build:api
    â†“
.output-api/
â”œâ”€â”€ server/
â””â”€â”€ index.mjs
    â†“
Upload para Lambda
```

**Em ExecuÃ§Ã£o:**
```
Usuario acessa: https://estÃ¡ticos.com
                      â†“
    CloudFront serve HTML/JS/CSS
    (Assets estÃ¡ticos prÃ©-compilados)
                      â†“
   Script Vue executa no navegador
                      â†“
   POST /api/chat â†’ https://api.estÃ¡ticos.com
                      â†“
              Lambda Function
          (Node.js + LangChain puro)
                      â†“
         Retorna resposta com streaming
```

**Vantagens para ProduÃ§Ã£o:**
- âœ… **Cold starts reduzidos**: Lambda contÃ©m apenas LangChain (~15MB) + dependÃªncias
  - Resultado: 3-5 segundos no primeiro request
- âœ… **Scaling independente**: Se frontend Ã© acessado muito, CDN absorve. Se backend Ã© pesado, Lambda escala Ã  parte
- âœ… **Cache agressivo**: S3 + CloudFront cacheia assets por anos
- âœ… **Assets globais**: CDN distribui JS/CSS pelo mundo
- âœ… **SeparaÃ§Ã£o de responsabilidades**: Frontend versionado separado do backend

**Desvantagens:**
- âŒ **Complexidade aumenta**: Gerenciar 2 builds, 2 deployments, 2 repos
- âŒ **Setup inicial**: Precisa configurar CloudFront, S3, origem do CORS
- âŒ **Custo**: S3 + CloudFront adiciona custo (porÃ©m mÃ­nimo para MVP)

---

#### ğŸ“Š ComparaÃ§Ã£o Lado a Lado

| Aspecto | Nuxt Full-Stack (Atual) | Node + Vue Separados |
|--------|-------------------------|----------------------|
| **Cold Start** | 10-30s | 3-5s |
| **Tamanho Bundle** | 20-30MB | 15MB (API) + 2MB (Frontend) |
| **Complexidade** | Baixa | MÃ©dia |
| **Deploy** | Um comando | Dois comandos (2 pipelines) |
| **Cache Frontend** | Nenhum (sempre do Lambda) | Agressivo (CDN) |
| **Custo Mensal** | ~$0.20 (poucos reqs) | ~$1-3 (inclui CDN) |
| **Escalabilidade** | Ruim | Excelente |
| **Recomendado para** | MVP, protÃ³tipos | ProduÃ§Ã£o, alto trÃ¡fego |

---

#### ğŸ¬ Roadmap Sugerido

1. **Fase 1 (MVP - Atual)**: Nuxt Full-Stack
   - VÃ¡lido para <100 reqs/dia
   - Prototipa rÃ¡pido
   - Deploy simples

2. **Fase 2 (Beta - ~1 mÃªs)**: SeparaÃ§Ã£o de builds
   - MantÃ©m monorepo Ãºnico
   - Scripts `build:frontend` e `build:api`
   - Deployments independentes mas no mesmo repo

3. **Fase 3 (ProduÃ§Ã£o)**: Monorepo split
   - 2 repositÃ³rios (`frontend` e `backend-api`)
   - CI/CD pipelines completamente separadas
   - Scaling independente

---

#### ğŸ’¡ Resposta TÃ©cnica: Como Funciona?

**Por que ambos vÃ£o juntos para Lambda atualmente?**

Quando vocÃª executa `npm run build` no Nuxt:

1. Nuxt compila o Vue em componentes reativos
2. Nuxt compila o `/server` em mÃ³dulos Node.js
3. Tudo Ã© empacotado em `.output/` com um Ãºnico `index.mjs`
4. VocÃª faz zip de `.output/` e upload para Lambda
5. Lambda executa `index.mjs`, que:
   - Inicia um servidor Node.js na porta 3000
   - Quando recebe GET `/`, renderiza HTML do Vue
   - Quando recebe POST `/api/chat`, executa o handler do server

**Resultado**: Uma Ãºnica funÃ§Ã£o Lambda atende ambos.

**Vantagem futura**: VocÃª pode exportar apenas o `/server` compilado para uma Lambda separada sem alterar cÃ³digo (apenas CI/CD).


## 3. Fluxo de Trabalho Git (PadrÃ£o Standard)

Seguiremos rigorosamente este fluxo para organizaÃ§Ã£o.

### Regras de Branch
1. **Nunca** commitar na `main` ou `develop` diretamente
2. Toda branch nasce da `develop`
3. Toda branch morre (merge) na `develop`

### Nomenclatura
PadrÃ£o: `DDMMYY-Feature-Description`

#### Formato
- **DDMMYY**: Data no formato dia/mÃªs/ano (2 dÃ­gitos cada)
- **Feature**: Nome da feature em kebab-case
- **Description**: DescriÃ§Ã£o adicional em kebab-case

#### Exemplos
041125-DB-schemas-review-refactor
031225-Notifications-V2-implementation
031225-Alerts-refactor-remove-airlines
031225-Redis-optimization-monthly-quotas
031225-Moblix-V2-integration
#### Regras
- Use kebab-case (palavras separadas por hÃ­fens)
- Seja descritivo mas conciso
- Inclua a data de criaÃ§Ã£o da branch
- Use maiÃºsculas apenas para siglas (V2, API, DB)

### Fluxo Simplificado

#### Estrutura
```
Feature Branch â†’ develop â†’ master
```

#### Fluxo Detalhado

1. **Criar branch de feature**
   ```bash
   git checkout develop
   git pull origin develop
   git checkout -b 081225-project-setup
   ```

2. **Desenvolver feature**
   - MÃºltiplos commits organizados
   - Commits seguindo Conventional Commits
   - Data jÃ¡ estÃ¡ no nome da branch (nÃ£o repetir nos commits)

3. **Criar Pull Request**
   - PR: `081225-project-setup` â†’ `develop`
   - Adicionar descriÃ§Ã£o clara
   - Linkar issues relacionadas

4. **Merge em develop**
   - ApÃ³s code review e aprovaÃ§Ã£o
   - Testes passando
   - Sem conflitos
   - Merges frequente na branch develop

5. **Merge em master**
   - Apenas quando funÃ§Ã£o de alto nÃ­vel estiver completa
   - Testes passando
   - DocumentaÃ§Ã£o atualizada
   - CoordenaÃ§Ã£o com frontend alinhada

### Regra: Sempre Partir de Develop

**Todas as branches de feature devem SEMPRE ser criadas a partir de `develop`.**

#### Por quÃª?

1. **`develop` Ã© a branch de integraÃ§Ã£o estÃ¡vel**
   - ContÃ©m todas as features jÃ¡ mergeadas e testadas
   - Ã‰ o ponto de referÃªncia comum para todo o time

2. **Evita dependÃªncias entre features**
   - Cada feature Ã© independente
   - NÃ£o cria dependÃªncias desnecessÃ¡rias entre branches

3. **Facilita o merge posterior**
   - Menos conflitos ao fazer merge em `develop`
   - HistÃ³rico mais limpo e organizado

4. **MantÃ©m todas as features no mesmo ponto de partida**
   - Garante consistÃªncia entre diferentes features
   - Facilita code review e testes

#### Workflow Correto

```bash
# 1. SEMPRE voltar para develop primeiro
git checkout develop

# 2. Atualizar develop com o remoto (importante!)
git pull origin develop

# 3. Criar nova branch de feature a partir de develop atualizada
git checkout -b 081225-project-setup

# 4. Agora trabalhar na feature
git add <arquivos>
git commit -m "feat(setup): ..."
```

#### O Que NÃƒO Fazer

```bash
# âŒ ERRADO - Criar branch a partir de outra feature branch
git checkout 091225-backend-logic
git checkout -b 101225-frontend-ui  # ERRADO!

# âŒ ERRADO - Criar branch sem atualizar develop primeiro
git checkout develop
git checkout -b 081225-project-setup  # Pode estar desatualizada!
```

### PrincÃ­pios
- **Features**: Merge direto em `develop` via PR
- **Master**: Merge apenas quando funÃ§Ã£o completa e testada
- **Develop**: Sempre estÃ¡vel para basear trabalho

### Conventional Commits

#### Formato
```
<tipo>(<escopo>): <descriÃ§Ã£o>
```

#### Tipos Comuns
- `feat`: Nova funcionalidade
- `fix`: CorreÃ§Ã£o de bug
- `docs`: DocumentaÃ§Ã£o
- `style`: FormataÃ§Ã£o (sem mudanÃ§a de cÃ³digo)
- `refactor`: RefatoraÃ§Ã£o
- `perf`: Melhoria de performance
- `test`: Testes
- `chore`: Tarefas de manutenÃ§Ã£o
- `ci`: CI/CD
- `build`: Build system

#### Exemplos
```bash
feat(auth): adiciona login com Google OAuth
fix(payment): corrige cÃ¡lculo de desconto
docs(readme): atualiza instruÃ§Ãµes de instalaÃ§Ã£o
refactor(api): simplifica validaÃ§Ã£o de dados
```

#### Primeira Linha
- Use o imperativo: "adiciona", "corrige", "atualiza"
- NÃ£o use: "adicionado", "corrigido", "atualizado"
- Seja especÃ­fico e claro
- Evite mensagens genÃ©ricas como "update" ou "fix"

#### Boas PrÃ¡ticas
- Um commit = uma mudanÃ§a lÃ³gica
- Commits pequenos e frequentes
- Teste antes de commitar
- Use o corpo para explicar o "porquÃª" quando necessÃ¡rio

#### Estrutura Completa

```
<tipo>(<escopo>): <assunto curto>

<corpo opcional explicando o porquÃª>

<rodapÃ© opcional com referÃªncias>
```

#### Exemplo Completo
```bash
feat(api): adiciona endpoint de busca de usuÃ¡rios

Implementa busca paginada com filtros por nome e email.
Isso melhora a performance em listas grandes de usuÃ¡rios.

Closes #123
```

#### Exemplos de Boas Mensagens
```bash
feat(chat): adiciona componente ChatMessage
feat(api): implementa endpoint de streaming
feat(rag): integra Qdrant para busca vetorial
refactor(ui): simplifica lÃ³gica de LocalStorage
fix(stream): corrige encoding de caracteres especiais
docs(readme): atualiza instruÃ§Ãµes de instalaÃ§Ã£o
```

#### Exemplos de Mensagens a Evitar
```bash
# âŒ Evite
update
fix
changes
WIP
test

# âœ… Prefira
feat(chat): adiciona componente ChatMessage
fix(stream): corrige encoding de caracteres especiais
refactor(ui): simplifica lÃ³gica de LocalStorage
```

---

## 4. Roteiro de ImplementaÃ§Ã£o (Roadmap)

Siga esta ordem exata para evitar bloqueios.

### Fase 0: Setup Inicial
* **Branch:** `project-setup`
* **Tarefas:**
    * Init Nuxt 3
    * Install LangChain/OpenAI libs
    * Configurar `.env`

### Fase 1: O "CÃ©rebro" (IngestÃ£o de Dados)
* **Branch:** `rag-ingestion-implementation`
* **Tarefas:**
    * Criar endpoint `server/api/ingest.post.ts`
    * Receber PDF via multipart/form-data
    * Processar com LangChain (`PDFLoader` + `RecursiveCharacterTextSplitter`)
    * Gerar Embeddings e salvar no Qdrant
    * Criar componente `DocumentUpload.vue` (drag & drop)
* *Nota:* O upload agora Ã© feito via interface web, nÃ£o por script local

### Fase 2: O Backend LÃ³gico
* **Branch:** `backend-logic-implementation`
* **Tarefas:**
    * Criar rota Nitro `server/api/chat.post.ts`
    * Receber `{ question, history }`
    * Configurar conexÃ£o Qdrant + OpenAI via LangChain
    * Testar resposta texto simples (sem stream)

### Fase 3: O Frontend Visual
* **Branch:** `frontend-ui-implementation`
* **Tarefas:**
    * Layout do Chat
    * LÃ³gica de `LocalStorage` (Salvar histÃ³rico)
    * Envio do Payload completo para a API

### Fase 4: O Streaming (IntegraÃ§Ã£o Final)
* **Branch:** `streaming-implementation`
* **Tarefas:**
    * **Back:** Mudar resposta para `sendStream` com iterÃ¡vel do LangChain
    * **Front:** Mudar `fetch` para usar `getReader()` e montar texto em tempo real
    * **Infra:** Configurar `serverless.yml` com `invokeMode: RESPONSE_STREAM`

---

## 5. ImplementaÃ§Ã£o TÃ©cnica de ReferÃªncia

### 5.1 Endpoints da API

O projeto possui **2 endpoints principais**:

#### 5.1.1 `/api/ingest` - Upload de Documentos

Endpoint para fazer upload de PDFs e processar para o Qdrant.

**Request:**
```http
POST /api/ingest
Content-Type: multipart/form-data

file: <PDF_FILE>
```

**Response:**
Retorna JSON com status de sucesso, nÃºmero de chunks processados e ID do documento.

**Detalhes de ImplementaÃ§Ã£o:**
Ver cÃ³digo em `server/api/ingest.post.ts` para implementaÃ§Ã£o completa com PDFLoader, RecursiveCharacterTextSplitter e integraÃ§Ã£o Qdrant.

#### 5.1.2 `/api/chat` - ConversaÃ§Ã£o com Streaming

Endpoint para conversar com o chatbot. Retorna resposta via streaming.

**Request:**
```http
POST /api/chat
Content-Type: application/json
x-user-id: <UUID>

{
  "question": "Qual Ã© o conteÃºdo do documento?",
  "history": [
    { "role": "user", "content": "Pergunta anterior" },
    { "role": "assistant", "content": "Resposta anterior" }
  ]
}
```

**Response:**
```http
Content-Type: text/event-stream

[Streaming de texto em tempo real]
```

**ImplementaÃ§Ã£o:** Ver seÃ§Ã£o 5.2

### 5.2 Arquivo de ConfiguraÃ§Ã£o (`serverless.yml`)

ConfiguraÃ§Ã£o vital para o streaming funcionar na AWS.

**Pontos Principais:**
- `invokeMode: RESPONSE_STREAM` - Essencial para streaming funcionar
- `timeout: 30` - Timeout de 30 segundos para processar requisiÃ§Ãµes
- `memorySize: 512` - MemÃ³ria RAM alocada para a Lambda
- VariÃ¡veis de ambiente carregadas via `serverless-dotenv-plugin`

### 5.3 LÃ³gica de Streaming no Nitro (`server/api/chat.post.ts`)

**Fluxo de Streaming:**
1. Recebe `{ question, history }` do frontend
2. Transforma histÃ³rico JSON em objetos LangChain (HumanMessage, AIMessage)
3. Configura ChatOpenAI com `streaming: true`
4. Cria Chain com prompt template + LLM + output parser
5. Configura headers HTTP (`Content-Type: text/event-stream`)
6. Executa chain e converte para ReadableStream
7. Retorna stream usando `sendStream(event, readable)`

**Ver implementaÃ§Ã£o completa em:** `server/api/chat.post.ts`

### 5.4 Guia de ImplementaÃ§Ã£o AWS Serverless (Credenciais + Deploy)

**Resumo direto**
- **Para que servem as chaves (Access Key / Secret):** credenciais de usuÃ¡rio IAM para o CLI (Serverless Framework / AWS CLI) autenticar na sua conta AWS e criar/atualizar recursos. Sem elas, o `serverless deploy` nÃ£o tem permissÃ£o para subir nada.
- **Quem usa:** o prÃ³prio `serverless deploy` (via AWS SDK) e qualquer comando AWS CLI. NÃ£o sÃ£o usadas pelo cÃ³digo do app em runtime e nÃ£o vÃ£o dentro do bundle.
- **Onde ficam:** o comando `serverless config credentials --provider aws --key ... --secret ...` salva em `~/.aws/credentials` (e `~/.aws/config`), fora do projeto e fora do Git.
- **RelaÃ§Ã£o com `serverless.yml`:**
  - O `serverless.yml` descreve o que criar na AWS: serviÃ§o `rag-chatbot-mvp`, runtime `nodejs18.x`, regiÃ£o `us-east-1`, funÃ§Ã£o `api` apontando para `.output/server/index.handler`, URL pÃºblica com CORS e streaming, timeout/memÃ³ria e variÃ¡veis de ambiente do Lambda.
  - Ao rodar `serverless deploy`, o Serverless Framework lÃª o `serverless.yml`, empacota o handler e usa as credenciais do `~/.aws/credentials` para provisionar/atualizar a Lambda + URL.
  - As variÃ¡veis em `environment:` (`OPENAI_API_KEY`, `QDRANT_URL`, etc.) sÃ£o injetadas no runtime da Lambda a partir do ambiente do deploy (via `.env` + `serverless-dotenv-plugin` ou variÃ¡veis do CI). **NÃ£o** devem conter as chaves IAM; essas ficam sÃ³ no perfil local/CI para autenticaÃ§Ã£o do deploy.

**Resumo prÃ¡tico**
1) Guarde as chaves IAM apenas em `~/.aws/credentials` (ou variÃ¡veis de ambiente no CI).
2) Coloque apenas as variÃ¡veis do app em `.env` (OpenAI/Qdrant etc.).
3) Rode `pnpm build` para gerar `.output/server/index.handler`.
4) Rode `serverless deploy`: ele usa as credenciais locais para falar com a AWS e criar/atualizar a Lambda conforme o `serverless.yml`.

#### ğŸ“Œ Guia passo a passo (AWS + Serverless)

##### Fase 1: O Terreno (AWS Root)
Objetivo: ter uma conta ativa na nuvem.
1. Acessar `aws.amazon.com` e criar a conta (root user) com email, pagamento e verificaÃ§Ã£o.

##### Fase 2: O CrachÃ¡ do RobÃ´ (IAM User)
Objetivo: gerar chaves para o Serverless Framework atuar na conta.
1. No console AWS, abrir **IAM > Users > Create User** (ex: `serverless-admin`).
2. Em **Permissions**, usar **Attach policies directly** â†’ `AdministratorAccess` (para facilitar o MVP).
3. Abrir o usuÃ¡rio criado â†’ aba **Security Credentials** â†’ **Access Keys** â†’ **Create access key** â†’ opÃ§Ã£o **Command Line Interface (CLI)**.
4. Copiar `Access Key ID` e `Secret Access Key` (guardar em local seguro).

##### Fase 3: Configurar o "crachÃ¡" no Serverless Framework
Objetivo: instalar a ferramenta e armazenar as credenciais localmente.
```bash
npm install -g serverless
serverless config credentials --provider aws --key SUA_ACCESS_KEY --secret SUA_SECRET_KEY
```
*Esse comando salva em `~/.aws/credentials` para o Serverless usar sempre. NÃ£o vai para o repo.*

##### Fase 4: Preparar o Projeto Nuxt
Objetivo: deixar o cÃ³digo pronto para empacotar.
```bash
pnpm add -D serverless-dotenv-plugin

# Criar .env na raiz (exemplo)
OPENAI_API_KEY=sk-proj-...
QDRANT_URL=https://...
QDRANT_API_KEY=th-...

# Conferir serverless.yml (resumo)
service: rag-chatbot-mvp
frameworkVersion: '3'
provider:
  name: aws
  runtime: nodejs18.x
  region: us-east-1
  environment:
    OPENAI_API_KEY: ${env:OPENAI_API_KEY}
    QDRANT_URL: ${env:QDRANT_URL}
    QDRANT_API_KEY: ${env:QDRANT_API_KEY}
functions:
  api:
    handler: .output/server/index.handler
    url:
      cors: true
      invokeMode: RESPONSE_STREAM
    timeout: 30
plugins:
  - serverless-dotenv-plugin
```

##### Fase 5: Build e Deploy
Objetivo: compilar o Nuxt e enviar para a AWS.
```bash
pnpm build          # gera .output
serverless deploy   # lÃª o serverless.yml e faz o upload
```
ApÃ³s o deploy, o terminal retorna a Function URL pÃºblica (ex: `https://xyz.lambda-url.us-east-1.on.aws`).

---

### ğŸ“¦ O que `pnpm run deploy:api` faz?

O script `deploy:api` executa dois comandos em sequÃªncia:

```bash
"deploy:api": "pnpm build && serverless deploy --verbose"
```

#### 1ï¸âƒ£ `pnpm build` â†’ Executa `nuxt build`:
- Compila o cÃ³digo Vue/Nuxt (TypeScript â†’ JavaScript)
- Gera a pasta `.output/server/` com o cÃ³digo otimizado para Lambda
- Faz **tree-shaking** (remove cÃ³digo nÃ£o usado)
- Faz **minificaÃ§Ã£o** (reduz tamanho dos arquivos)
- Faz **bundling** de dependÃªncias em um Ãºnico arquivo (`index.mjs` de ~208 KB)

#### 2ï¸âƒ£ `serverless deploy` â†’ Pega o `.output/server/` e:
- Cria o ZIP (~517 KB)
- Faz upload para S3
- Cria/atualiza a Lambda Function na AWS
- Retorna a Function URL pÃºblica

#### ğŸ¤” Por que o build Ã© necessÃ¡rio?

| Uso | Precisa do Build? | Motivo |
|-----|-------------------|--------|
| **Lambda (API)** | âœ… SIM | Lambda precisa do cÃ³digo compilado em `.output/server/` |
| **Frontend Docker Local** | âœ… SIM | TambÃ©m usa o build do Nuxt, mas com preset diferente (`node-server`) |

O build Ã© **essencial** para o Lambda porque:

1. **Transforma TypeScript â†’ JavaScript**: Lambda nÃ£o executa TypeScript nativamente
2. **Bundla dependÃªncias**: Todas as deps sÃ£o empacotadas em um Ãºnico arquivo (`index.mjs`)
3. **Otimiza para produÃ§Ã£o**: Remove cÃ³digo de desenvolvimento, minifica, tree-shake
4. **Reduz tamanho**: De ~500 MB (`node_modules` raiz) para ~2 MB (`.output/server/`)

**Resultado final do build:**
```
.output/server/
â”œâ”€â”€ index.mjs       (208 KB) â† CÃ³digo da aplicaÃ§Ã£o + deps bundladas
â”œâ”€â”€ package.json    (673 B)  â† Metadados mÃ­nimos
â””â”€â”€ node_modules/   (~1.5 MB) â† Apenas deps que nÃ£o podem ser bundladas
```

---

## 6. ğŸ“¦ OtimizaÃ§Ã£o de Bundle: API-Only vs Full-Stack

### ğŸ¯ Por que Full-Stack funcionou mas API-Only nÃ£o?

Durante o desenvolvimento, encontramos um problema curioso: o modo **Full-Stack funcionou de primeira**, mas o **API-Only dava erro de tamanho** (130 MB). 

**A resposta:** O problema **nunca foi o build do Nuxt** - foi a **configuraÃ§Ã£o do `serverless.yml`!**

---

#### ğŸ” O que realmente aconteceu

O build do Nuxt **sempre funcionou corretamente** em ambos os modos:

```
Build do Nuxt (.output/):
â”œâ”€â”€ public/     (500 KB)  â† Assets frontend (sÃ³ no Full-Stack)
â””â”€â”€ server/     (2 MB)    â† Backend otimizado
    â””â”€â”€ node_modules/ (1.5 MB) â† Deps bundladas
```

O problema estava no **empacotamento do Serverless Framework**, nÃ£o no build.

---

#### âœ… Full-Stack (funcionou de primeira)

```yaml
# serverless.yml Full-Stack
package:
  patterns:
    - '.output/**'           # Inclui .output/public + .output/server
    - '!node_modules/**'     # Exclui node_modules raiz
```

**O que o Serverless empacotava:**
```
ZIP enviado (~3.5 MB):
â”œâ”€â”€ .output/public/  âœ… (500 KB)
â”œâ”€â”€ .output/server/  âœ… (2 MB)
â””â”€â”€ node_modules/    âŒ ExcluÃ­do corretamente
```

**Por que funcionou?** O pattern `.output/**` era especÃ­fico o suficiente para que o Serverless nÃ£o "vazasse" outros arquivos.

---

#### âŒ API-Only (nÃ£o funcionou - ANTES de arrumar)

```yaml
# serverless.yml API-Only (ANTES)
package:
  patterns:
    - '.output/server/**'    # Inclui server
    - '!node_modules/**'     # DEVERIA excluir, mas...
```

**O que o Serverless REALMENTE empacotava:**
```
ZIP enviado (~130 MB):
â”œâ”€â”€ .output/server/  âœ… (2 MB)
â”œâ”€â”€ node_modules/    âŒ (500 MB) â† DA RAIZ! ğŸ˜±
```

**Por que falhou?** O Serverless Framework faz um **glob match** na raiz do projeto. Como `.output/server/**` nÃ£o cobre "tudo", ele ainda procurava outros arquivos e **encontrava o `node_modules/` da raiz do projeto**.

A exclusÃ£o `!node_modules/**` nÃ£o funcionava bem porque a **ordem dos patterns** estava errada.

---

#### âœ… API-Only (funcionou - DEPOIS de arrumar)

```yaml
# serverless.yml API-Only (DEPOIS)
package:
  patterns:
    - '!**'                          # 1ï¸âƒ£ Exclui ABSOLUTAMENTE TUDO
    - '!node_modules/**'             # 2ï¸âƒ£ Garante exclusÃ£o extra
    - '.output/server/index.mjs'     # 3ï¸âƒ£ Inclui APENAS o necessÃ¡rio
    - '.output/server/package.json'
    - '.output/server/node_modules/**'
```

**O que o Serverless empacota agora:**
```
ZIP enviado (~517 KB):
â”œâ”€â”€ .output/server/index.mjs      âœ… (208 KB)
â”œâ”€â”€ .output/server/package.json   âœ… (673 B)
â””â”€â”€ .output/server/node_modules/  âœ… (1.5 MB)
```

**Por que funciona?** O `!**` exclui **absolutamente tudo** primeiro, e depois incluÃ­mos **apenas** os arquivos especÃ­ficos que precisamos.

---

#### ğŸ“Š Tabela Comparativa Final

| Aspecto | Full-Stack | API-Only (antes) | API-Only (depois) |
|---------|------------|------------------|-------------------|
| **Build Nuxt** | âœ… Mesmo (~2 MB) | âœ… Mesmo (~2 MB) | âœ… Mesmo (~2 MB) |
| **O que QUERIA enviar** | `.output/` inteiro | Apenas `.output/server/` | Apenas `.output/server/` |
| **O que REALMENTE enviou** | âœ… `.output/` (~3.5 MB) | âŒ `.output/server/` + `node_modules/` raiz (~130 MB) | âœ… `.output/server/` (~517 KB) |
| **Pattern inicial** | `.output/**` | `.output/server/**` | `!**` |
| **node_modules raiz incluÃ­do?** | âŒ NÃ£o | âœ… SIM (bug!) | âŒ NÃ£o |
| **Tamanho ZIP final** | ~3.5 MB âœ… | ~130 MB âŒ | ~517 KB âœ… |

---

#### ğŸ’¡ LiÃ§Ã£o Aprendida

**Resumo:** Nos dois casos (Full-Stack e API-Only):
1. VocÃª fazia o build â†’ `pnpm build` â†’ gerava `.output/` otimizado (~2-3 MB)
2. VocÃª jogava a build no Lambda â†’ `serverless deploy`

**O que aconteceu:**
- âœ… O build **sempre funcionou**
- âœ… A lÃ³gica de "Full-Stack = tudo, API-Only = sÃ³ server" estava **certa**
- âŒ O `serverless.yml` do API-Only tinha patterns que **vazavam o `node_modules/` raiz**

**Por que Full-Stack funcionou "por sorte":**  
O pattern `.output/**` era especÃ­fico o suficiente para que o Serverless nÃ£o "vazasse" outros arquivos.

**Por que API-Only falhou:**  
O pattern `.output/server/**` era menos abrangente, e o Serverless Framework ainda buscava outros arquivos na raiz, encontrando o `node_modules/` de 500 MB.

> **A soluÃ§Ã£o:** `'!**'` primeiro para garantir que **nada vaze**.

---

### ğŸŒ httpApi vs Function URL: Por que um funcionou e o outro nÃ£o?

Durante o desenvolvimento, testamos duas abordagens para expor a Lambda:

#### âŒ Function URL (nÃ£o funcionou inicialmente)

```yaml
functions:
  api:
    url:
      cors: true
      invokeMode: RESPONSE_STREAM
```

**Problema:** O Serverless Framework v3 criava a Function URL com `AuthType: AWS_IAM` por padrÃ£o, exigindo credenciais AWS assinadas para acesso. Resultado: **403 Forbidden** para requisiÃ§Ãµes pÃºblicas.

**Por que isso aconteceu:**
- Function URLs sÃ£o um recurso mais novo da AWS (2022)
- O Serverless Framework nÃ£o tinha controle total sobre o `AuthType` via sintaxe simples
- Mesmo especificando `cors: true`, a URL era criada como privada

**SoluÃ§Ã£o temporÃ¡ria:** Executar `aws lambda update-function-url-config --auth-type NONE` manualmente apÃ³s cada deploy.

**SoluÃ§Ã£o permanente:** Adicionar recurso CloudFormation customizado para forÃ§ar `AuthType: NONE`.

---

#### âœ… API Gateway HTTP API (funcionou de primeira)

```yaml
functions:
  api:
    events:
      - httpApi: '*'
```

**Por que funcionou:**
- API Gateway HTTP API Ã© um serviÃ§o mais maduro e amplamente suportado
- O Serverless Framework tem controle total sobre as configuraÃ§Ãµes
- Por padrÃ£o, cria endpoints **pÃºblicos** (sem autenticaÃ§Ã£o)
- Rota coringa `*` captura todas as requisiÃ§Ãµes e repassa para a Lambda

**Vantagens:**
- âœ… Deploy determinÃ­stico (sempre pÃºblico)
- âœ… CORS configurÃ¡vel via provider
- âœ… Suporte a custom domains
- âœ… MÃ©tricas e logs integrados

**Desvantagens:**
- âŒ Limite de timeout de 30 segundos (vs 15 minutos na Function URL)
- âŒ NÃ£o suporta `RESPONSE_STREAM` nativo (streaming funciona mas com overhead)
- âŒ Custo adicional mÃ­nimo (mas irrelevante para MVP)

---

#### ğŸ“Š ComparaÃ§Ã£o Final

| Aspecto | Function URL | API Gateway HTTP API |
|---------|--------------|----------------------|
| **AuthType padrÃ£o (Serverless)** | `AWS_IAM` âŒ | PÃºblico âœ… |
| **Timeout mÃ¡ximo** | 15 minutos | 30 segundos |
| **Streaming nativo** | âœ… `RESPONSE_STREAM` | âš ï¸ Via chunks |
| **ConfiguraÃ§Ã£o** | Requer CloudFormation extra | âœ… Funciona out-of-the-box |
| **Custo** | Gratuito | +$1/milhÃ£o de requisiÃ§Ãµes |
| **RecomendaÃ§Ã£o MVP** | âš ï¸ Requer setup extra | âœ… **Use este** |

---

#### ğŸ¤” ConfusÃ£o Comum: "Mas httpApi nÃ£o aceita streaming?"

**Resposta curta:** Aceita sim! Mas de forma diferente.

**Como funciona:**

| MÃ©todo | Function URL (`RESPONSE_STREAM`) | API Gateway (`httpApi`) |
|--------|----------------------------------|-------------------------|
| **Tipo** | Streaming nativo da Lambda | HTTP Transfer-Encoding: chunked |
| **ImplementaÃ§Ã£o** | Lambda envia chunks diretamente | Lambda retorna body, Gateway repassa em chunks |
| **Cliente** | Recebe chunks em tempo real | Recebe chunks em tempo real |
| **Resultado** | âœ… Funciona | âœ… Funciona |

**Em ambos os casos**, seu cÃ³digo no cliente usa o **mesmo** `fetch` + `ReadableStream`:

```ts
const response = await fetch('/api/chat', { method: 'POST', body: ... })
const reader = response.body.getReader()
while (true) {
  const { done, value } = await reader.read()
  if (done) break
  console.log(new TextDecoder().decode(value)) // chunks chegam aqui
}
```

**A diferenÃ§a estÃ¡ no backend:**

```ts
// Function URL (RESPONSE_STREAM)
export const handler = awslambda.streamifyResponse(async (event, responseStream) => {
  responseStream.write('chunk1\n')
  responseStream.write('chunk2\n')
  responseStream.end()
})

// API Gateway (HTTP chunked) - mais simples!
export default defineEventHandler(async (event) => {
  const stream = new ReadableStream(...)
  return stream // Nuxt/Nitro cuida do resto
})
```

**ConclusÃ£o:** Com `httpApi`, o streaming funciona perfeitamente para chat. A Ãºnica limitaÃ§Ã£o real Ã© o **timeout de 30s**.

---

#### ğŸ¯ Como Implementar Streaming: Suas OpÃ§Ãµes

Se vocÃª quer streaming de resposta no chat, tem duas opÃ§Ãµes:

##### âœ… OpÃ§Ã£o 1: httpApi (Atual) - **RECOMENDADO**

**Status:** JÃ¡ configurado e funcionando

```yaml
functions:
  api:
    events:
      - httpApi: '*'
```

**Vantagens:**
- âœ… Streaming jÃ¡ funciona (HTTP Transfer-Encoding: chunked)
- âœ… Zero mudanÃ§as no cÃ³digo
- âœ… PÃºblico por padrÃ£o (sem 403 Forbidden)
- âœ… Setup simples

**Desvantagens:**
- âš ï¸ Timeout de 30s (suficiente para 99% dos casos de chat)

**MudanÃ§as necessÃ¡rias no cÃ³digo:** **NENHUMA** âœ¨

---

##### âš ï¸ OpÃ§Ã£o 2: Function URL com RESPONSE_STREAM

**Status:** Requer configuraÃ§Ã£o adicional

```yaml
functions:
  api:
    handler: .output/server/index.handler
    url:
      cors: true
      invokeMode: RESPONSE_STREAM
    timeout: 120
    memorySize: 512

# Adicionar no final do serverless.yml
resources:
  Resources:
    ApiLambdaFunctionUrl:
      Type: AWS::Lambda::Url
      Properties:
        AuthType: NONE  # â† Crucial para acesso pÃºblico
        TargetFunctionArn: !GetAtt ApiLambdaFunction.Arn
        InvokeMode: RESPONSE_STREAM
        Cors:
          AllowOrigins: ["*"]
          AllowMethods: ["*"]
          AllowHeaders: ["*"]
    
    ApiLambdaPermissionFnUrl:
      Type: AWS::Lambda::Permission
      Properties:
        FunctionName: !Ref ApiLambdaFunction
        Action: lambda:InvokeFunctionUrl
        Principal: "*"
        FunctionUrlAuthType: NONE
```

**Vantagens:**
- âœ… Streaming nativo da Lambda
- âœ… Timeout atÃ© 15 minutos

**Desvantagens:**
- âŒ Requer configuraÃ§Ã£o CloudFormation extra
- âŒ Precisa modificar handlers para usar `streamifyResponse`
- âŒ Precisa instalar `@aws-lambda-powertools/streamify`

**MudanÃ§as necessÃ¡rias no cÃ³digo:**

```ts
// ANTES (funciona com httpApi)
export default defineEventHandler(async (event) => {
  const stream = new ReadableStream({
    async start(controller) {
      controller.enqueue('chunk1\n')
      controller.close()
    }
  })
  return stream
})

// DEPOIS (para RESPONSE_STREAM)
import { streamifyResponse } from '@aws-lambda-powertools/streamify'

export const handler = streamifyResponse(async (event, responseStream) => {
  responseStream.write('chunk1\n')
  responseStream.end()
})
```

---

##### ğŸ“Š ComparaÃ§Ã£o de EsforÃ§o

| Aspecto | httpApi (OpÃ§Ã£o 1) | Function URL (OpÃ§Ã£o 2) |
|---------|-------------------|------------------------|
| **Config no serverless.yml** | âœ… JÃ¡ estÃ¡ | âš ï¸ Adicionar resources (20 linhas) |
| **MudanÃ§a no cÃ³digo** | âœ… Zero | âŒ Reescrever todos os handlers |
| **Instalar dependÃªncias** | âœ… Nada | âŒ `pnpm add @aws-lambda-powertools` |
| **Streaming funciona** | âœ… Sim | âœ… Sim |
| **Timeout** | 30s | 15 min |
| **PÃºblico por padrÃ£o** | âœ… Sim | âš ï¸ SÃ³ com CloudFormation |

---

##### ğŸ’¡ RecomendaÃ§Ã£o Final

**Use httpApi (OpÃ§Ã£o 1)** porque:

1. **Streaming jÃ¡ funciona** - seu cÃ³digo atual com `ReadableStream` funciona perfeitamente
2. **30s Ã© suficiente** - respostas de chat GPT raramente excedem 10s
3. **Zero trabalho extra** - nÃ£o precisa mudar absolutamente nada
4. **Simples e confiÃ¡vel** - menos pontos de falha

**SÃ³ use Function URL (OpÃ§Ã£o 2) se:**
- VocÃª realmente precisa de respostas >30s (muito raro)
- Quer experimentar streaming nativo por curiosidade tÃ©cnica
- EstÃ¡ disposto a reescrever todos os handlers

---

### ğŸš« Bloqueando Rotas de Frontend no Modo API-Only

Quando vocÃª faz deploy apenas da API, ainda pode acontecer do SSR do Nuxt tentar renderizar pÃ¡ginas HTML. Aqui estÃ¡ como bloquear completamente.

#### âœ… Resultado Esperado

```bash
# âŒ Rota raiz bloqueada
$ curl https://sua-api.execute-api.sa-east-1.amazonaws.com
{"message":"Not Found"}  # 404 do API Gateway

# âœ… Rotas /api/* funcionam
$ curl https://sua-api.execute-api.sa-east-1.amazonaws.com/api/chat
{"message":"Chat endpoint - a ser implementado"}  # JSON puro
```

---

#### ğŸ”§ SoluÃ§Ã£o 1: Bloquear no API Gateway (RECOMENDADO)

Configure rotas especÃ­ficas no `serverless.yml`:

```yaml
functions:
  api:
    handler: .output/server/index.handler
    events:
      # Bloquear rotas de frontend - sÃ³ permite /api/*
      - httpApi:
          path: /api/{proxy+}
          method: ANY
      - httpApi:
          path: /api/chat
          method: POST
      - httpApi:
          path: /api/ingest
          method: POST
```

**Vantagem:** O API Gateway retorna **404 antes de chegar na Lambda** â†’ economia de custo e latÃªncia.

---

#### ğŸ”§ SoluÃ§Ã£o 2: ForÃ§ar Content-Type nos Handlers

Adicione `setResponseHeader` em **todos os endpoints**:

```typescript
// server/api/chat.post.ts
export default defineEventHandler(async (event) => {
  // ForÃ§ar resposta JSON (evita SSR renderizar HTML)
  setResponseHeader(event, 'Content-Type', 'application/json')
  
  return {
    message: 'Chat endpoint - a ser implementado'
  }
})
```

**Por que precisa disso?**

O Nuxt tem um **sistema de rotas universal** que tenta renderizar pÃ¡ginas HTML mesmo para rotas `/api/*` quando vocÃª retorna um objeto simples. Ao definir `Content-Type: application/json`, vocÃª forÃ§a o Nuxt a enviar JSON puro sem passar pelo SSR.

---

#### ğŸ”§ SoluÃ§Ã£o 3: Middleware Global (Opcional)

Adicione um middleware que bloqueia tudo exceto `/api/*`:

```typescript
// server/middleware/api-only.ts
export default defineEventHandler((event) => {
  const path = event.path || event.node.req.url || ''
  
  // Permitir apenas rotas /api/*
  if (!path.startsWith('/api/')) {
    throw createError({
      statusCode: 404,
      statusMessage: 'Not Found',
      message: 'API-only mode. Frontend runs locally in Docker.'
    })
  }
})
```

**Vantagem:** Bloqueia globalmente, mas a Lambda ainda processa a request.

---

#### ğŸ“Š Qual usar?

| Abordagem | Bloqueia Onde | Vantagem | Desvantagem |
|-----------|---------------|----------|-------------|
| **SoluÃ§Ã£o 1: httpApi paths** | API Gateway | NÃ£o chega na Lambda | Precisa listar todas as rotas |
| **SoluÃ§Ã£o 2: Content-Type** | Handler | Simples, 1 linha | Precisa em todos os endpoints |
| **SoluÃ§Ã£o 3: Middleware** | Nitro/Nuxt | Global, 3 linhas | Lambda processa antes de bloquear |

**RecomendaÃ§Ã£o:** **SoluÃ§Ã£o 1 + 2** (bloquear no Gateway + forÃ§ar JSON nos handlers).

---

### ğŸ”§ BÃ´nus: O que o Build do Nuxt/Nitro faz automaticamente

Embora o problema tenha sido no `serverless.yml`, Ã© Ãºtil entender que o **Nitro jÃ¡ otimiza** o build automaticamente:

#### OtimizaÃ§Ãµes automÃ¡ticas do Nitro:
- âœ… Remove `test/`, `docs/`, `examples/` folders
- âœ… Remove `*.md`, `*.map` files
- âœ… Faz tree-shaking de cÃ³digo nÃ£o usado
- âœ… Minifica o cÃ³digo JavaScript
- âœ… Bundla dependÃªncias em um Ãºnico arquivo (`index.mjs`)

#### ConfiguraÃ§Ãµes extras no `nuxt.config.ts`:

```typescript
nitro: {
  preset: 'aws-lambda',
  serveStatic: false,
  minify: true,
  sourcemap: false,  // Remove source maps
  
  rollupConfig: {
    output: {
      format: 'esm',
      sourcemap: false
    }
  }
}
```

**Resultado do Build:**
```
.output/server/
â”œâ”€â”€ index.mjs       (208 KB) â† CÃ³digo bundlado
â”œâ”€â”€ package.json    (673 B)
â””â”€â”€ node_modules/   (~1.5 MB) â† Apenas deps nÃ£o bundlÃ¡veis
```

> **Importante:** Essas otimizaÃ§Ãµes do Nitro **sempre funcionaram**. O problema de 130 MB era porque o Serverless Framework incluÃ­a o `node_modules/` da **raiz do projeto** (500 MB), nÃ£o o `.output/server/node_modules/` otimizado.

---

#### âš™ï¸ ConfiguraÃ§Ã£o Final do serverless.yml

```yaml
package:
  patterns:
    - '!**'                     # 1. Exclui TUDO (primeira regra)
    - '!node_modules/**'        # 2. Garante exclusÃ£o de node_modules raiz
    - '!.nuxt/**'               # 3. Exclui cache do Nuxt
    - '!.git/**'                # 4. Exclui arquivos git
    - '.output/server/index.mjs'        # 5. Inclui sÃ³ o que precisa
    - '.output/server/package.json'
    - '.output/server/node_modules/**'  # 6. Inclui deps do build
```

**Por que isso funciona?**
1. `'!**'` exclui **absolutamente tudo** do projeto
2. Depois vocÃª adiciona de volta **apenas** os arquivos da pasta `.output/server/`
3. O `node_modules/` da raiz (500 MB) **nunca Ã© incluÃ­do**
4. Apenas o `node_modules/` otimizado dentro de `.output/server/` (2 MB) Ã© incluÃ­do

**Resultado real do projeto:**
```
Antes (ordem errada): 130 MB ZIP âŒ (incluÃ­a node_modules raiz)
Depois (ordem correta): 517 KB ZIP âœ… (apenas .output/server)
```

---

#### ğŸ“¦ OtimizaÃ§Ã£o de package.json: DevDependencies

Outra dica importante Ã© garantir que suas **dependÃªncias de desenvolvimento** estejam em `devDependencies`, nÃ£o em `dependencies`.

##### ğŸ¤” Por que isso importa?

Quando vocÃª roda `pnpm install --production` ou quando o Serverless Framework faz o bundle, ele **ignora** tudo que estÃ¡ em `devDependencies`. Isso reduz o tamanho final do pacote.

##### âœ… DependÃªncias que devem estar em `devDependencies`:

| Pacote | Por quÃª? |
|--------|----------|
| `dotenv` | Usado apenas em desenvolvimento (variÃ¡veis vÃ£o pro env da Lambda) |
| `serverless` | Ferramenta de CLI, nÃ£o roda em produÃ§Ã£o |
| `serverless-dotenv-plugin` | Plugin do Serverless, nÃ£o vai pro Lambda |
| `typescript` | Compilador, cÃ³digo final Ã© JS |
| `eslint`, `prettier` | Ferramentas de dev |
| `nodemon` | Dev server, nÃ£o usa em Lambda |
| `@types/*` | Types do TypeScript |
| `tsx` | Runtime de dev para TypeScript |

##### âœ… DependÃªncias que devem estar em `dependencies`:

| Pacote | Por quÃª? |
|--------|----------|
| `langchain`, `@langchain/*` | Usado em runtime |
| `openai` | Cliente da API OpenAI |
| `@qdrant/js-client-rest` | Cliente do Qdrant |
| `nuxt`, `vue` | Framework de runtime |
| `uuid` | Usado em runtime |

##### ğŸ“‹ Exemplo de package.json correto:

```json
{
  "dependencies": {
    "langchain": "^0.3.x",
    "@langchain/openai": "^0.5.x",
    "nuxt": "^3.x",
    "vue": "^3.x"
  },
  "devDependencies": {
    "dotenv": "^16.x",
    "serverless": "^3.x",
    "serverless-dotenv-plugin": "^6.x",
    "typescript": "^5.x",
    "@types/node": "^22.x"
  }
}
```

> **ğŸ’¡ Dica:** Execute `pnpm install` apÃ³s mover dependÃªncias para garantir que o `pnpm-lock.yaml` seja atualizado corretamente.

---

### ğŸ”— Alternativa: Lambda Layers

Se as otimizaÃ§Ãµes acima nÃ£o forem suficientes, a alternativa Ã© usar **Lambda Layers** para separar as dependÃªncias pesadas.

#### ğŸ¤” O que sÃ£o Lambda Layers?

Layers sÃ£o pacotes de cÃ³digo/dependÃªncias compartilhadas que podem ser reutilizadas por mÃºltiplas Lambda Functions. VocÃª sobe as deps uma vez e referencia em vÃ¡rias funÃ§Ãµes.

#### ğŸ“¦ Estrutura com Layers

```
meu-projeto/
â”œâ”€â”€ lambda-function/     (seu cÃ³digo - 5 MB)
â”‚   â”œâ”€â”€ index.mjs
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ layers/
â”‚   â”œâ”€â”€ langchain-layer/         (Layer 1: 50 MB)
â”‚   â”‚   â”œâ”€â”€ nodejs/node_modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ langchain/
â”‚   â”‚   â”‚   â”œâ”€â”€ @langchain/
â”‚   â”‚   â”‚   â””â”€â”€ encoding/
â”‚   â”‚   â””â”€â”€ layer.zip
â”‚   â”‚
â”‚   â””â”€â”€ openai-layer/            (Layer 2: 40 MB)
â”‚       â”œâ”€â”€ nodejs/node_modules/
â”‚       â”‚   â”œâ”€â”€ openai/
â”‚       â”‚   â””â”€â”€ axios/
â”‚       â””â”€â”€ layer.zip
â”‚
â””â”€â”€ serverless.yml  (referencia as layers)
```

#### âœ… Vantagens de Usar Layers

1. **SeparaÃ§Ã£o de preocupaÃ§Ãµes**: Cada layer tem responsabilidade clara
2. **ReutilizaÃ§Ã£o**: Mesma layer pode ser usada por mÃºltiplas funÃ§Ãµes
3. **Versionamento**: VocÃª versiona cada layer independentemente
4. **Tamanho menor**: FunÃ§Ã£o fica ~5 MB, layers compartilhadas (uploaded uma vez)
5. **Cold start mais rÃ¡pido**: Sem precisar descompactar 200+ MB
6. **AtualizaÃ§Ã£o independente**: Atualizar dependÃªncia nÃ£o redeploiya a funÃ§Ã£o inteira

#### âŒ Desvantagens

1. **Complexidade aumenta**: Mais configuraÃ§Ã£o no `serverless.yml`
2. **Limite de layers**: AWS permite atÃ© 5 layers por funÃ§Ã£o
3. **EspaÃ§o total**: Soma da funÃ§Ã£o + todas as layers nÃ£o pode exceder 250 MB descompactado
4. **Deployment mais lento**: Precisa fazer upload de mÃºltiplos ZIPs

#### ğŸ“‹ ImplementaÃ§Ã£o com Layers (Exemplo)

```yaml
# serverless.yml com Layers

service: rag-chatbot-mvp

plugins:
  - serverless-dotenv-plugin

provider:
  name: aws
  runtime: nodejs18.x
  region: sa-east-1

# ğŸ”¥ Definir Layers
layers:
  langchainLayer:
    path: layers/langchain
    name: rag-chatbot-langchain-${sls:stage}
    
  openaiLayer:
    path: layers/openai
    name: rag-chatbot-openai-${sls:stage}

functions:
  api:
    handler: .output/server/index.handler
    # ğŸ”¥ Referenciar layers
    layers:
      - !Ref LangchainLayerLambdaLayer
      - !Ref OpenaiLayerLambdaLayer
    url:
      cors: true
      invokeMode: RESPONSE_STREAM
    timeout: 120
    memorySize: 512
```

#### ğŸ› ï¸ Como Criar uma Layer

```bash
# 1. Criar estrutura de diretÃ³rios
mkdir -p layers/langchain/nodejs

# 2. Navegar e instalar deps
cd layers/langchain/nodejs
npm init -y
npm install langchain @langchain/core @langchain/community @langchain/openai

# 3. Compactar (a estrutura AWS espera nodejs/node_modules)
cd ..
zip -r langchain-layer.zip nodejs/

# 4. No serverless.yml, apontar para o ZIP
# (o path aponta para o arquivo ZIP ou para o diretÃ³rio)
```

#### ğŸ“Š Tamanho Comparativo

```
SEM Layers (Current):
â”œâ”€â”€ FunÃ§Ã£o ZIP: 130 MB âŒ Excede limite

COM Layers (Otimizado):
â”œâ”€â”€ FunÃ§Ã£o ZIP: 5 MB
â”œâ”€â”€ Langchain Layer: 50 MB (reutilizÃ¡vel)
â””â”€â”€ OpenAI Layer: 40 MB (reutilizÃ¡vel)
Total enviado: 95 MB (layers sÃ£o enviadas apenas uma vez) âœ…
```

#### ğŸ¯ Quando Usar Layers

- **Use Layers se:**
  - Bundle principal > 50 MB mesmo com otimizaÃ§Ãµes
  - VocÃª tem mÃºltiplas funÃ§Ãµes Lambda reutilizando as mesmas deps
  - Quer cold starts mais rÃ¡pidos
  - Precisa versionar dependÃªncias independentemente

- **NÃ£o use Layers se:**
  - Bundle < 50 MB (simples Ã© melhor)
  - FunÃ§Ã£o Ã© Ãºnica e nÃ£o Ã© reutilizada
  - Quer keep it simple para MVP

---

## 7. Estrutura do Projeto

```
Serverless-RAG-Chatbot-MVP-/
â”œâ”€â”€ .env.example                 # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                   # Arquivos ignorados pelo Git
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ package.json                 # DependÃªncias do projeto
â”œâ”€â”€ nuxt.config.ts               # ConfiguraÃ§Ã£o do Nuxt 3
â”œâ”€â”€ tsconfig.json                # ConfiguraÃ§Ã£o do TypeScript
â”œâ”€â”€ tailwind.config.js           # ConfiguraÃ§Ã£o do Tailwind CSS
â”œâ”€â”€ serverless.yml               # ConfiguraÃ§Ã£o de deploy AWS Lambda
â”‚
â”œâ”€â”€ app.vue                      # Componente raiz da aplicaÃ§Ã£o
â”œâ”€â”€ pages/                       # PÃ¡ginas da aplicaÃ§Ã£o
â”‚   â””â”€â”€ index.vue                # PÃ¡gina inicial (Chat UI)
â”‚
â”œâ”€â”€ components/                  # Componentes Vue reutilizÃ¡veis
â”‚   â”œâ”€â”€ ChatMessage.vue          # Componente de mensagem individual
â”‚   â”œâ”€â”€ ChatInput.vue            # Componente de input de mensagem
â”‚   â”œâ”€â”€ ChatWindow.vue           # Componente da janela de chat
â”‚   â”œâ”€â”€ ThemeToggle.vue          # Toggle de dark mode
â”‚   â””â”€â”€ DocumentUpload.vue       # Upload de PDF (drag & drop)
â”‚
â”œâ”€â”€ composables/                 # Composables Vue (lÃ³gica reutilizÃ¡vel)
â”‚   â”œâ”€â”€ useChatHistory.ts        # Gerenciamento do histÃ³rico no LocalStorage
â”‚   â””â”€â”€ useChatStream.ts         # LÃ³gica de streaming de mensagens
â”‚
â”œâ”€â”€ server/                      # Backend Nitro
â”‚   â”œâ”€â”€ api/                     # Rotas da API
â”‚   â”‚   â”œâ”€â”€ chat.post.ts         # Endpoint de conversaÃ§Ã£o (streaming)
â”‚   â”‚   â””â”€â”€ ingest.post.ts       # Endpoint de upload de PDF
â”‚   â”œâ”€â”€ utils/                   # UtilitÃ¡rios do servidor
â”‚   â”‚   â”œâ”€â”€ langchain.ts         # ConfiguraÃ§Ã£o do LangChain
â”‚   â”‚   â””â”€â”€ qdrant.ts            # ConfiguraÃ§Ã£o do Qdrant
â”‚   â””â”€â”€ middleware/              # Middleware do servidor
â”‚
â”œâ”€â”€ scripts/                     # Scripts auxiliares
â”‚   â”œâ”€â”€ ingest.ts                # Script de ingestÃ£o de PDF para Qdrant
â”‚   â””â”€â”€ README.md                # DocumentaÃ§Ã£o dos scripts
â”‚
â”œâ”€â”€ data/                        # Dados do projeto
â”‚   â””â”€â”€ documents/               # PDFs para ingestÃ£o
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ public/                      # Arquivos estÃ¡ticos
â”‚   â””â”€â”€ favicon.ico
â”‚
â””â”€â”€ assets/                      # Assets processados (CSS, imagens)
    â””â”€â”€ css/
        â””â”€â”€ main.css             # CSS global
```
